{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 101 NumPy Exercises for Data Analysis\n",
    "\n",
    "*by Selva Prabhakaran*\n",
    "\n",
    "From the website: https://www.machinelearningplus.com/python/101-numpy-exercises-python/\n",
    "\n",
    "*The goal of the numpy exercises is to serve as a reference as well as to get you to apply numpy beyond the basics.*\n",
    "*The questions are of 4 levels of difficulties with L1 being the easiest to L4 being the hardest.*\n",
    "\n",
    "**NOTE**: Run the next cell to load the data and the libraries needed for the exercises.\n",
    "\n",
    "**NOTE**: There is actually 70 of them, lol. ðŸ¤·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/krybacki/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /home/krybacki/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (10.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (L1) **Import numpy as `np` and print the version number.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.version.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (L1) **Create a 1D array of numbers from 0 to 9.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(0, 10)\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (L1) **Create a 3Ã—3 numpy array of all Trueâ€™s.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n",
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "all_trues = np.full((3, 3), True, dtype=bool)\n",
    "print(all_trues)\n",
    "\n",
    "all_trues = np.ones((3, 3), dtype=bool)\n",
    "print(all_trues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (L1) **Extract all odd numbers from `arr`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9] [1 3 5 7 9]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "arr = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "odd = arr[arr % 2 == 1]\n",
    "\n",
    "print(arr, odd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (L1) **Replace all odd numbers in `arr` with -1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 -1  2 -1  4 -1  6 -1  8 -1]\n"
     ]
    }
   ],
   "source": [
    "odds_replaced = arr.copy()\n",
    "odds_replaced[odds_replaced % 2 == 1] = -1\n",
    "print(odds_replaced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (L2) **Replace all odd numbers in arr with -1 without changing `arr`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 -1  2 -1  4 -1  6 -1  8 -1] [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "out_of_place_replace = np.where(arr % 2 == 1, -1, arr)\n",
    "print(out_of_place_replace, arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. (L1) **Convert a 1D array to a 2D array with 2 rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]]\n",
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "reshaped_arr = arr.reshape((2, 5))\n",
    "print(reshaped_arr)\n",
    "\n",
    "# -1 sets the dimension automatically\n",
    "reshaped_arr = arr.reshape((2, -1))\n",
    "print(reshaped_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. (L2) **Stack arrays `a` and `b` vertically.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]] [[1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n",
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "a = np.arange(10).reshape(2,-1)\n",
    "b = np.repeat(1, 10).reshape(2,-1)\n",
    "\n",
    "print(a, b)\n",
    "\n",
    "c = np.vstack([a, b])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. (L2) **Stack the arrays `a` and `b` horizontally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4 1 1 1 1 1]\n",
      " [5 6 7 8 9 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "d = np.hstack([a, b])\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. (L2) **Create the following pattern without hardcoding. Use only numpy functions and the below input array `a`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 2 2 2 3 3 3 1 2 3 1 2 3 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "a = np.array([1,2,3])\n",
    "\n",
    "# This repeats EACH ELEMENT along given axis\n",
    "b = a.repeat(3)\n",
    "\n",
    "# This repeats WHOLE ARRAY, as tiles\n",
    "triple_a = np.tile(a, 3)\n",
    "\n",
    "c = np.hstack([b, triple_a])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. (L2) **Get the common items between a and b.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4]\n",
      "[2 4]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "a = np.array([1,2,3,2,3,4,3,4,5,6])\n",
    "b = np.array([7,2,10,2,7,4,9,4,9,8])\n",
    "\n",
    "# Indexing and unique\n",
    "c = np.unique(a[a == b])\n",
    "print(c)\n",
    "\n",
    "# Via intersect method\n",
    "d = np.intersect1d(ar1=a, ar2=b)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. (L2) **How to remove from one array those items that exist in another?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "a = np.array([1,2,3,4,5])\n",
    "b = np.array([5,6,7,8,9])\n",
    "\n",
    "# Returns difference between arrays\n",
    "c = np.setdiff1d(a , b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. (L2) **Get the positions where elements of a and b match.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1, 3, 5, 7]),)\n",
      "(array([1, 3, 5, 7]),)\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "a = np.array([1,2,3,2,3,4,3,4,5,6])\n",
    "b = np.array([7,2,10,2,7,4,9,4,9,8])\n",
    "\n",
    "'''\n",
    "From docs: \n",
    "\n",
    "nonzero: Returns a tuple of arrays, one for each dimension of a, containing the indices of the non-zero elements in that dimension. The values in a are always tested and returned in row-major, C-style order.\n",
    "asarray: Convert the input to an array.\n",
    "'''\n",
    "\n",
    "c = np.asarray(a == b).nonzero()\n",
    "print(c)\n",
    "\n",
    "d = np.where(a == b)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. (L2) **Get all items between 5 and 10 from `a`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  9 10]\n",
      "[ 6  9 10]\n",
      "[ 6  9 10]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "a = np.array([2, 6, 1, 9, 10, 3, 27])\n",
    "\n",
    "# Middle ground\n",
    "b = a[np.where((a <= 10) & (a >= 5))]\n",
    "print(b)\n",
    "\n",
    "# Shorthand\n",
    "c = a[(a >= 5) & (a <= 10)]\n",
    "print(c)\n",
    "\n",
    "# Extended\n",
    "d = a[np.where(np.logical_and(a >=5, a <= 10))]\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. (L2) **Convert the function maxx that works on two scalars, to work on two arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 7 9 8 9 7 5]\n",
      "[6. 7. 9. 8. 9. 7. 5.]\n"
     ]
    }
   ],
   "source": [
    "# Base function\n",
    "def maxx(x, y):\n",
    "    \"\"\"Get the maximum of two items\"\"\"\n",
    "    if x >= y:\n",
    "        return x\n",
    "    else:\n",
    "        return y\n",
    "\n",
    "# Inputs\n",
    "a = np.array([5, 7, 9, 8, 6, 4, 5])\n",
    "b = np.array([6, 3, 4, 8, 9, 7, 1])\n",
    "\n",
    "# Direct definition\n",
    "def pair_max(input_a, input_b):\n",
    "    return np.where(input_a > input_b, input_a, input_b)\n",
    "\n",
    "result = pair_max(a, b)\n",
    "print(result)\n",
    "\n",
    "# Vectorize\n",
    "'''\n",
    "From docs:\n",
    "Returns an object that acts like pyfunc, but takes arrays as input.\n",
    "Define a vectorized function which takes a nested sequence of objects or numpy arrays as inputs and returns a single numpy array or a tuple of numpy arrays.\n",
    "The vectorized function evaluates pyfunc over successive tuples of the input arrays like the python map function, except it uses the broadcasting rules of numpy\n",
    "\n",
    "tl;dr - A map array method\n",
    "'''\n",
    "pair_max = np.vectorize(maxx, otypes=[float])\n",
    "\n",
    "result = pair_max(a, b)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. (L2) **Swap columns 1 and 2 in the array `arr`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "[[1 0 2]\n",
      " [4 3 5]\n",
      " [7 6 8]]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "arr = np.arange(9).reshape(3,3)\n",
    "print(arr)\n",
    "\n",
    "swapped_cols = arr[:, [1, 0, 2]]\n",
    "print(swapped_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. (L2) **Swap rows 1 and 2 in the array `arr`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 4 5]\n",
      " [0 1 2]\n",
      " [6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "swapped_rows = arr[[1, 0, 2], :]\n",
    "print(swapped_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. (L2) **Reverse the rows of a 2D array `arr`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 7 8]\n",
      " [3 4 5]\n",
      " [0 1 2]]\n",
      "[[6 7 8]\n",
      " [3 4 5]\n",
      " [0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "# Via flip\n",
    "reversed_rows = np.flip(arr, axis=0)\n",
    "print(reversed_rows)\n",
    "\n",
    "# w/ fancy indexing\n",
    "print(arr[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. (L2) **Reverse the columns of a 2D array `arr`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 0]\n",
      " [5 4 3]\n",
      " [8 7 6]]\n"
     ]
    }
   ],
   "source": [
    "# Via flip\n",
    "reversed_cols = np.flip(arr, axis=1)\n",
    "print(reversed_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. (L2) **Create a 2D array of shape 5x3 to contain random decimal numbers between 5 and 10.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.79128264 7.38806759 8.1757195 ]\n",
      " [5.71424504 8.61436668 9.07662141]\n",
      " [7.43911417 8.06328349 8.91768736]\n",
      " [6.89172514 5.80153485 7.28053673]\n",
      " [6.61805795 7.18816882 5.97671225]]\n",
      "[[6.71173875 7.02527264 5.63805213]\n",
      " [8.71508405 5.83269018 6.03751013]\n",
      " [7.32754015 8.95440265 8.10042707]\n",
      " [6.29456717 9.28984949 5.80723521]\n",
      " [9.91640407 8.96313073 8.74890102]]\n"
     ]
    }
   ],
   "source": [
    "MIN = 5\n",
    "MAX = 10\n",
    "\n",
    "# Manual sampling from uniform dist\n",
    "random_arr = (MAX - MIN) * np.random.random_sample((5, 3)) + MIN\n",
    "print(random_arr)\n",
    "\n",
    "# Sampling from uniform distribution via uniform() method\n",
    "random_arr = np.random.uniform(MIN, MAX, (5,3))\n",
    "print(random_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. (L2) **Print or show only 3 decimal places of the numpy array `rand`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.687 0.698 0.154]\n",
      " [0.591 0.663 0.441]\n",
      " [0.621 0.02  0.93 ]\n",
      " [0.085 0.928 0.196]\n",
      " [0.323 0.417 0.834]]\n",
      "[[0.687 0.698 0.154]\n",
      " [0.591 0.663 0.441]\n",
      " [0.621 0.02  0.93 ]\n",
      " [0.085 0.928 0.196]\n",
      " [0.323 0.417 0.834]]\n"
     ]
    }
   ],
   "source": [
    "rand = np.random.random((5,3))\n",
    "\n",
    "# Using printoptions as ctx manager makes the changes temporary!\n",
    "with np.printoptions(precision=3):\n",
    "    print(rand)\n",
    "\n",
    "# Manual change and revert\n",
    "np.set_printoptions(precision=3)\n",
    "print(rand)\n",
    "\n",
    "## A \"Meyer's\" reset for printoptions\n",
    "np.set_printoptions(\n",
    "    edgeitems=3,\n",
    "    infstr='inf',\n",
    "    linewidth=75,\n",
    "    nanstr='nan',\n",
    "    precision=8,\n",
    "    suppress=False,\n",
    "    threshold=1000,\n",
    "    formatter=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. (L2) **Pretty print `rand` by suppressing the scientific notation (like 1e10).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0005434  0.00027837 0.00042452]\n",
      " [0.00084478 0.00000472 0.00012157]\n",
      " [0.00067075 0.00082585 0.00013671]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "rand = np.random.random([3,3])/1e3\n",
    "with np.printoptions(suppress=True):\n",
    "    print(rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. (L1) **Limit the number of items printed in python numpy array a to a maximum of 6 elements.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2 ... 12 13 14]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(15)\n",
    "with np.printoptions(threshold=6):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. (L1) **Print the full numpy array a without truncating.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
     ]
    }
   ],
   "source": [
    "with np.printoptions(threshold=None):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25. (L2) **Import the iris dataset keeping the text intact.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'5.1' b'3.5' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'4.9' b'3.0' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'4.7' b'3.2' b'1.3' b'0.2' b'Iris-setosa']\n",
      " [b'4.6' b'3.1' b'1.5' b'0.2' b'Iris-setosa']\n",
      " [b'5.0' b'3.6' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'5.4' b'3.9' b'1.7' b'0.4' b'Iris-setosa']\n",
      " [b'4.6' b'3.4' b'1.4' b'0.3' b'Iris-setosa']\n",
      " [b'5.0' b'3.4' b'1.5' b'0.2' b'Iris-setosa']\n",
      " [b'4.4' b'2.9' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'4.9' b'3.1' b'1.5' b'0.1' b'Iris-setosa']\n",
      " [b'5.4' b'3.7' b'1.5' b'0.2' b'Iris-setosa']\n",
      " [b'4.8' b'3.4' b'1.6' b'0.2' b'Iris-setosa']\n",
      " [b'4.8' b'3.0' b'1.4' b'0.1' b'Iris-setosa']\n",
      " [b'4.3' b'3.0' b'1.1' b'0.1' b'Iris-setosa']\n",
      " [b'5.8' b'4.0' b'1.2' b'0.2' b'Iris-setosa']\n",
      " [b'5.7' b'4.4' b'1.5' b'0.4' b'Iris-setosa']\n",
      " [b'5.4' b'3.9' b'1.3' b'0.4' b'Iris-setosa']\n",
      " [b'5.1' b'3.5' b'1.4' b'0.3' b'Iris-setosa']\n",
      " [b'5.7' b'3.8' b'1.7' b'0.3' b'Iris-setosa']\n",
      " [b'5.1' b'3.8' b'1.5' b'0.3' b'Iris-setosa']\n",
      " [b'5.4' b'3.4' b'1.7' b'0.2' b'Iris-setosa']\n",
      " [b'5.1' b'3.7' b'1.5' b'0.4' b'Iris-setosa']\n",
      " [b'4.6' b'3.6' b'1.0' b'0.2' b'Iris-setosa']\n",
      " [b'5.1' b'3.3' b'1.7' b'0.5' b'Iris-setosa']\n",
      " [b'4.8' b'3.4' b'1.9' b'0.2' b'Iris-setosa']\n",
      " [b'5.0' b'3.0' b'1.6' b'0.2' b'Iris-setosa']\n",
      " [b'5.0' b'3.4' b'1.6' b'0.4' b'Iris-setosa']\n",
      " [b'5.2' b'3.5' b'1.5' b'0.2' b'Iris-setosa']\n",
      " [b'5.2' b'3.4' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'4.7' b'3.2' b'1.6' b'0.2' b'Iris-setosa']\n",
      " [b'4.8' b'3.1' b'1.6' b'0.2' b'Iris-setosa']\n",
      " [b'5.4' b'3.4' b'1.5' b'0.4' b'Iris-setosa']\n",
      " [b'5.2' b'4.1' b'1.5' b'0.1' b'Iris-setosa']\n",
      " [b'5.5' b'4.2' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'4.9' b'3.1' b'1.5' b'0.1' b'Iris-setosa']\n",
      " [b'5.0' b'3.2' b'1.2' b'0.2' b'Iris-setosa']\n",
      " [b'5.5' b'3.5' b'1.3' b'0.2' b'Iris-setosa']\n",
      " [b'4.9' b'3.1' b'1.5' b'0.1' b'Iris-setosa']\n",
      " [b'4.4' b'3.0' b'1.3' b'0.2' b'Iris-setosa']\n",
      " [b'5.1' b'3.4' b'1.5' b'0.2' b'Iris-setosa']\n",
      " [b'5.0' b'3.5' b'1.3' b'0.3' b'Iris-setosa']\n",
      " [b'4.5' b'2.3' b'1.3' b'0.3' b'Iris-setosa']\n",
      " [b'4.4' b'3.2' b'1.3' b'0.2' b'Iris-setosa']\n",
      " [b'5.0' b'3.5' b'1.6' b'0.6' b'Iris-setosa']\n",
      " [b'5.1' b'3.8' b'1.9' b'0.4' b'Iris-setosa']\n",
      " [b'4.8' b'3.0' b'1.4' b'0.3' b'Iris-setosa']\n",
      " [b'5.1' b'3.8' b'1.6' b'0.2' b'Iris-setosa']\n",
      " [b'4.6' b'3.2' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'5.3' b'3.7' b'1.5' b'0.2' b'Iris-setosa']\n",
      " [b'5.0' b'3.3' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'7.0' b'3.2' b'4.7' b'1.4' b'Iris-versicolor']\n",
      " [b'6.4' b'3.2' b'4.5' b'1.5' b'Iris-versicolor']\n",
      " [b'6.9' b'3.1' b'4.9' b'1.5' b'Iris-versicolor']\n",
      " [b'5.5' b'2.3' b'4.0' b'1.3' b'Iris-versicolor']\n",
      " [b'6.5' b'2.8' b'4.6' b'1.5' b'Iris-versicolor']\n",
      " [b'5.7' b'2.8' b'4.5' b'1.3' b'Iris-versicolor']\n",
      " [b'6.3' b'3.3' b'4.7' b'1.6' b'Iris-versicolor']\n",
      " [b'4.9' b'2.4' b'3.3' b'1.0' b'Iris-versicolor']\n",
      " [b'6.6' b'2.9' b'4.6' b'1.3' b'Iris-versicolor']\n",
      " [b'5.2' b'2.7' b'3.9' b'1.4' b'Iris-versicolor']\n",
      " [b'5.0' b'2.0' b'3.5' b'1.0' b'Iris-versicolor']\n",
      " [b'5.9' b'3.0' b'4.2' b'1.5' b'Iris-versicolor']\n",
      " [b'6.0' b'2.2' b'4.0' b'1.0' b'Iris-versicolor']\n",
      " [b'6.1' b'2.9' b'4.7' b'1.4' b'Iris-versicolor']\n",
      " [b'5.6' b'2.9' b'3.6' b'1.3' b'Iris-versicolor']\n",
      " [b'6.7' b'3.1' b'4.4' b'1.4' b'Iris-versicolor']\n",
      " [b'5.6' b'3.0' b'4.5' b'1.5' b'Iris-versicolor']\n",
      " [b'5.8' b'2.7' b'4.1' b'1.0' b'Iris-versicolor']\n",
      " [b'6.2' b'2.2' b'4.5' b'1.5' b'Iris-versicolor']\n",
      " [b'5.6' b'2.5' b'3.9' b'1.1' b'Iris-versicolor']\n",
      " [b'5.9' b'3.2' b'4.8' b'1.8' b'Iris-versicolor']\n",
      " [b'6.1' b'2.8' b'4.0' b'1.3' b'Iris-versicolor']\n",
      " [b'6.3' b'2.5' b'4.9' b'1.5' b'Iris-versicolor']\n",
      " [b'6.1' b'2.8' b'4.7' b'1.2' b'Iris-versicolor']\n",
      " [b'6.4' b'2.9' b'4.3' b'1.3' b'Iris-versicolor']\n",
      " [b'6.6' b'3.0' b'4.4' b'1.4' b'Iris-versicolor']\n",
      " [b'6.8' b'2.8' b'4.8' b'1.4' b'Iris-versicolor']\n",
      " [b'6.7' b'3.0' b'5.0' b'1.7' b'Iris-versicolor']\n",
      " [b'6.0' b'2.9' b'4.5' b'1.5' b'Iris-versicolor']\n",
      " [b'5.7' b'2.6' b'3.5' b'1.0' b'Iris-versicolor']\n",
      " [b'5.5' b'2.4' b'3.8' b'1.1' b'Iris-versicolor']\n",
      " [b'5.5' b'2.4' b'3.7' b'1.0' b'Iris-versicolor']\n",
      " [b'5.8' b'2.7' b'3.9' b'1.2' b'Iris-versicolor']\n",
      " [b'6.0' b'2.7' b'5.1' b'1.6' b'Iris-versicolor']\n",
      " [b'5.4' b'3.0' b'4.5' b'1.5' b'Iris-versicolor']\n",
      " [b'6.0' b'3.4' b'4.5' b'1.6' b'Iris-versicolor']\n",
      " [b'6.7' b'3.1' b'4.7' b'1.5' b'Iris-versicolor']\n",
      " [b'6.3' b'2.3' b'4.4' b'1.3' b'Iris-versicolor']\n",
      " [b'5.6' b'3.0' b'4.1' b'1.3' b'Iris-versicolor']\n",
      " [b'5.5' b'2.5' b'4.0' b'1.3' b'Iris-versicolor']\n",
      " [b'5.5' b'2.6' b'4.4' b'1.2' b'Iris-versicolor']\n",
      " [b'6.1' b'3.0' b'4.6' b'1.4' b'Iris-versicolor']\n",
      " [b'5.8' b'2.6' b'4.0' b'1.2' b'Iris-versicolor']\n",
      " [b'5.0' b'2.3' b'3.3' b'1.0' b'Iris-versicolor']\n",
      " [b'5.6' b'2.7' b'4.2' b'1.3' b'Iris-versicolor']\n",
      " [b'5.7' b'3.0' b'4.2' b'1.2' b'Iris-versicolor']\n",
      " [b'5.7' b'2.9' b'4.2' b'1.3' b'Iris-versicolor']\n",
      " [b'6.2' b'2.9' b'4.3' b'1.3' b'Iris-versicolor']\n",
      " [b'5.1' b'2.5' b'3.0' b'1.1' b'Iris-versicolor']\n",
      " [b'5.7' b'2.8' b'4.1' b'1.3' b'Iris-versicolor']\n",
      " [b'6.3' b'3.3' b'6.0' b'2.5' b'Iris-virginica']\n",
      " [b'5.8' b'2.7' b'5.1' b'1.9' b'Iris-virginica']\n",
      " [b'7.1' b'3.0' b'5.9' b'2.1' b'Iris-virginica']\n",
      " [b'6.3' b'2.9' b'5.6' b'1.8' b'Iris-virginica']\n",
      " [b'6.5' b'3.0' b'5.8' b'2.2' b'Iris-virginica']\n",
      " [b'7.6' b'3.0' b'6.6' b'2.1' b'Iris-virginica']\n",
      " [b'4.9' b'2.5' b'4.5' b'1.7' b'Iris-virginica']\n",
      " [b'7.3' b'2.9' b'6.3' b'1.8' b'Iris-virginica']\n",
      " [b'6.7' b'2.5' b'5.8' b'1.8' b'Iris-virginica']\n",
      " [b'7.2' b'3.6' b'6.1' b'2.5' b'Iris-virginica']\n",
      " [b'6.5' b'3.2' b'5.1' b'2.0' b'Iris-virginica']\n",
      " [b'6.4' b'2.7' b'5.3' b'1.9' b'Iris-virginica']\n",
      " [b'6.8' b'3.0' b'5.5' b'2.1' b'Iris-virginica']\n",
      " [b'5.7' b'2.5' b'5.0' b'2.0' b'Iris-virginica']\n",
      " [b'5.8' b'2.8' b'5.1' b'2.4' b'Iris-virginica']\n",
      " [b'6.4' b'3.2' b'5.3' b'2.3' b'Iris-virginica']\n",
      " [b'6.5' b'3.0' b'5.5' b'1.8' b'Iris-virginica']\n",
      " [b'7.7' b'3.8' b'6.7' b'2.2' b'Iris-virginica']\n",
      " [b'7.7' b'2.6' b'6.9' b'2.3' b'Iris-virginica']\n",
      " [b'6.0' b'2.2' b'5.0' b'1.5' b'Iris-virginica']\n",
      " [b'6.9' b'3.2' b'5.7' b'2.3' b'Iris-virginica']\n",
      " [b'5.6' b'2.8' b'4.9' b'2.0' b'Iris-virginica']\n",
      " [b'7.7' b'2.8' b'6.7' b'2.0' b'Iris-virginica']\n",
      " [b'6.3' b'2.7' b'4.9' b'1.8' b'Iris-virginica']\n",
      " [b'6.7' b'3.3' b'5.7' b'2.1' b'Iris-virginica']\n",
      " [b'7.2' b'3.2' b'6.0' b'1.8' b'Iris-virginica']\n",
      " [b'6.2' b'2.8' b'4.8' b'1.8' b'Iris-virginica']\n",
      " [b'6.1' b'3.0' b'4.9' b'1.8' b'Iris-virginica']\n",
      " [b'6.4' b'2.8' b'5.6' b'2.1' b'Iris-virginica']\n",
      " [b'7.2' b'3.0' b'5.8' b'1.6' b'Iris-virginica']\n",
      " [b'7.4' b'2.8' b'6.1' b'1.9' b'Iris-virginica']\n",
      " [b'7.9' b'3.8' b'6.4' b'2.0' b'Iris-virginica']\n",
      " [b'6.4' b'2.8' b'5.6' b'2.2' b'Iris-virginica']\n",
      " [b'6.3' b'2.8' b'5.1' b'1.5' b'Iris-virginica']\n",
      " [b'6.1' b'2.6' b'5.6' b'1.4' b'Iris-virginica']\n",
      " [b'7.7' b'3.0' b'6.1' b'2.3' b'Iris-virginica']\n",
      " [b'6.3' b'3.4' b'5.6' b'2.4' b'Iris-virginica']\n",
      " [b'6.4' b'3.1' b'5.5' b'1.8' b'Iris-virginica']\n",
      " [b'6.0' b'3.0' b'4.8' b'1.8' b'Iris-virginica']\n",
      " [b'6.9' b'3.1' b'5.4' b'2.1' b'Iris-virginica']\n",
      " [b'6.7' b'3.1' b'5.6' b'2.4' b'Iris-virginica']\n",
      " [b'6.9' b'3.1' b'5.1' b'2.3' b'Iris-virginica']\n",
      " [b'5.8' b'2.7' b'5.1' b'1.9' b'Iris-virginica']\n",
      " [b'6.8' b'3.2' b'5.9' b'2.3' b'Iris-virginica']\n",
      " [b'6.7' b'3.3' b'5.7' b'2.5' b'Iris-virginica']\n",
      " [b'6.7' b'3.0' b'5.2' b'2.3' b'Iris-virginica']\n",
      " [b'6.3' b'2.5' b'5.0' b'1.9' b'Iris-virginica']\n",
      " [b'6.5' b'3.0' b'5.2' b'2.0' b'Iris-virginica']\n",
      " [b'6.2' b'3.4' b'5.4' b'2.3' b'Iris-virginica']\n",
      " [b'5.9' b'3.0' b'5.1' b'1.8' b'Iris-virginica']]\n"
     ]
    }
   ],
   "source": [
    "IRIS_DATASET_URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "\n",
    "# None or object returns an ARRAY of ROWS (as tuples)\n",
    "# since dtypes are not uniform and defined across all columns\n",
    "iris_dataset = np.genfromtxt(IRIS_DATASET_URL, delimiter=',', dtype=object)\n",
    "print(iris_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26. (L2) **Extract the text column species from the 1D iris imported in previous question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-setosa', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-versicolor', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica', b'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "COLUMN_NAMES = ('sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'species')\n",
    "\n",
    "species = [\n",
    "    row[4]\n",
    "    for row in iris_dataset\n",
    "]\n",
    "print(species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27. (L2) **Convert the 1D iris to 2D array iris_2d by omitting the species text field.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "\n",
    "# Removing string column makes all columns of uniform type, so it can be inferred\n",
    "# and NumPy sees that it must be a matrix of floats\n",
    "iris_2d = np.genfromtxt(url, delimiter=',', dtype=None, usecols=[0,1,2,3])\n",
    "\n",
    "print(iris_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28. (L1) **Find the mean, median, standard deviation of iris's sepallength (1st column).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.843333333333334\n",
      "5.8\n",
      "0.8253012917851409\n"
     ]
    }
   ],
   "source": [
    "for measure in (np.mean, np.median, np.std):\n",
    "    print(\n",
    "        measure(\n",
    "            iris_2d[:,0]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29. (L2) **Create a normalized form of iris's sepallength whose values range exactly between 0 and 1 so that the minimum has value 0 and maximum has value 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22222222 0.16666667 0.11111111 0.08333333 0.19444444 0.30555556\n",
      " 0.08333333 0.19444444 0.02777778 0.16666667 0.30555556 0.13888889\n",
      " 0.13888889 0.         0.41666667 0.38888889 0.30555556 0.22222222\n",
      " 0.38888889 0.22222222 0.30555556 0.22222222 0.08333333 0.22222222\n",
      " 0.13888889 0.19444444 0.19444444 0.25       0.25       0.11111111\n",
      " 0.13888889 0.30555556 0.25       0.33333333 0.16666667 0.19444444\n",
      " 0.33333333 0.16666667 0.02777778 0.22222222 0.19444444 0.05555556\n",
      " 0.02777778 0.19444444 0.22222222 0.13888889 0.22222222 0.08333333\n",
      " 0.27777778 0.19444444 0.75       0.58333333 0.72222222 0.33333333\n",
      " 0.61111111 0.38888889 0.55555556 0.16666667 0.63888889 0.25\n",
      " 0.19444444 0.44444444 0.47222222 0.5        0.36111111 0.66666667\n",
      " 0.36111111 0.41666667 0.52777778 0.36111111 0.44444444 0.5\n",
      " 0.55555556 0.5        0.58333333 0.63888889 0.69444444 0.66666667\n",
      " 0.47222222 0.38888889 0.33333333 0.33333333 0.41666667 0.47222222\n",
      " 0.30555556 0.47222222 0.66666667 0.55555556 0.36111111 0.33333333\n",
      " 0.33333333 0.5        0.41666667 0.19444444 0.36111111 0.38888889\n",
      " 0.38888889 0.52777778 0.22222222 0.38888889 0.55555556 0.41666667\n",
      " 0.77777778 0.55555556 0.61111111 0.91666667 0.16666667 0.83333333\n",
      " 0.66666667 0.80555556 0.61111111 0.58333333 0.69444444 0.38888889\n",
      " 0.41666667 0.58333333 0.61111111 0.94444444 0.94444444 0.47222222\n",
      " 0.72222222 0.36111111 0.94444444 0.55555556 0.66666667 0.80555556\n",
      " 0.52777778 0.5        0.58333333 0.80555556 0.86111111 1.\n",
      " 0.58333333 0.55555556 0.5        0.94444444 0.55555556 0.58333333\n",
      " 0.47222222 0.72222222 0.66666667 0.72222222 0.41666667 0.69444444\n",
      " 0.66666667 0.66666667 0.55555556 0.61111111 0.52777778 0.44444444]\n"
     ]
    }
   ],
   "source": [
    "sepallength = iris_2d[:,0]\n",
    "\n",
    "maximum_sepallength = np.max(sepallength)\n",
    "minimum_sepallength = np.min(sepallength)\n",
    "\n",
    "normalized_sepallength = (sepallength.copy() - minimum_sepallength) / (maximum_sepallength - minimum_sepallength)\n",
    "print(normalized_sepallength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30. (L3) **Compute the softmax score of sepallength.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.002 0.002 0.001 0.001 0.002 0.003 0.001 0.002 0.001 0.002 0.003 0.002\n",
      " 0.002 0.001 0.004 0.004 0.003 0.002 0.004 0.002 0.003 0.002 0.001 0.002\n",
      " 0.002 0.002 0.002 0.002 0.002 0.001 0.002 0.003 0.002 0.003 0.002 0.002\n",
      " 0.003 0.002 0.001 0.002 0.002 0.001 0.001 0.002 0.002 0.002 0.002 0.001\n",
      " 0.003 0.002 0.015 0.008 0.013 0.003 0.009 0.004 0.007 0.002 0.01  0.002\n",
      " 0.002 0.005 0.005 0.006 0.004 0.011 0.004 0.004 0.007 0.004 0.005 0.006\n",
      " 0.007 0.006 0.008 0.01  0.012 0.011 0.005 0.004 0.003 0.003 0.004 0.005\n",
      " 0.003 0.005 0.011 0.007 0.004 0.003 0.003 0.006 0.004 0.002 0.004 0.004\n",
      " 0.004 0.007 0.002 0.004 0.007 0.004 0.016 0.007 0.009 0.027 0.002 0.02\n",
      " 0.011 0.018 0.009 0.008 0.012 0.004 0.004 0.008 0.009 0.03  0.03  0.005\n",
      " 0.013 0.004 0.03  0.007 0.011 0.018 0.007 0.006 0.008 0.018 0.022 0.037\n",
      " 0.008 0.007 0.006 0.03  0.007 0.008 0.005 0.013 0.011 0.013 0.004 0.012\n",
      " 0.011 0.011 0.007 0.009 0.007 0.005]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/34968722/how-to-implement-the-softmax-function-in-python\n",
    "softmax_exponentials = np.exp(sepallength - np.max(sepallength))\n",
    "softmax = softmax_exponentials / softmax_exponentials.sum(axis=0)\n",
    "\n",
    "with np.printoptions(precision=3):\n",
    "    print(softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31. (L1) **Find the 5th and 95th percentile of iris's sepallength.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6 7.254999999999998\n",
      "[4.6   7.255]\n"
     ]
    }
   ],
   "source": [
    "five_percentile, nine_five_percentile = np.percentile(sepallength, 5), np.percentile(sepallength, 95)\n",
    "print(five_percentile, nine_five_percentile)\n",
    "\n",
    "# Doing both at once\n",
    "print(\n",
    "    np.percentile(sepallength, [5, 95])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32. (L1) **Insert np.nan values at 20 random positions in iris_2d dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  nan 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 nan 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [nan 3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 nan 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [nan 2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [nan 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 nan 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  nan 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 nan 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [nan 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 nan 1.8]\n",
      " [nan 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 nan 5.8 1.6]\n",
      " [7.4 nan 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 nan 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  nan 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 nan 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 nan 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 nan 5.9 2.3]\n",
      " [6.7 nan 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "iris_with_random_nans = iris_2d.copy()\n",
    "iris_with_random_nans[\n",
    "    np.random.choice(iris_with_random_nans.shape[0] - 1, size=20),\n",
    "    np.random.choice(iris_with_random_nans.shape[1] - 1, size=20)\n",
    "] = np.nan\n",
    "print(iris_with_random_nans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33. (L2) **Find the number and position of missing values in iris_2d's sepallength (1st column).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4   1]\n",
      " [ 24   1]\n",
      " [ 49   0]\n",
      " [ 58   2]\n",
      " [ 60   0]\n",
      " [ 67   0]\n",
      " [ 86   2]\n",
      " [ 91   2]\n",
      " [ 93   2]\n",
      " [100   0]\n",
      " [107   2]\n",
      " [108   0]\n",
      " [129   1]\n",
      " [130   1]\n",
      " [132   2]\n",
      " [135   2]\n",
      " [137   1]\n",
      " [141   2]\n",
      " [143   1]\n",
      " [144   1]] 20\n"
     ]
    }
   ],
   "source": [
    "nan_indices = np.argwhere(\n",
    "    np.isnan(iris_with_random_nans)\n",
    ")\n",
    "print(nan_indices, nan_indices.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34. (L2) **Filter the rows of iris_2d that has petallength (3rd column) > 1.5 and sepallength (1st column) < 5.0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [4.9, 2.5, 4.5, 1.7]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_2d[\n",
    "    np.logical_and(\n",
    "        iris_2d[:,2] > 1.5,\n",
    "        iris_2d[:,0] < 5.0\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35. (L2) **Select the rows of iris_2d that does not have any nan value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "non_nan_entries = iris_2d[\n",
    "    np.argwhere(\n",
    "        iris_2d != np.nan\n",
    "    )\n",
    "]\n",
    "print(np.nan in np.unique(non_nan_entries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36. (L2) **Find the correlation between SepalLength(1st column) and PetalLength(3rd column) in `iris_2d`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.87175416]\n",
      " [0.87175416 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "petallength = iris_2d[:,2]\n",
    "\n",
    "correlation = np.corrcoef(x=sepallength, y=petallength)\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "37. (L2) **Find out if `iris_2d` has any missing values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nans = np.isnan(iris_2d)\n",
    "nans.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38. (L2) **Replace all occurrences of nan with 0 in numpy array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "nanified_iris_2d = iris_2d.copy()\n",
    "nanified_iris_2d[np.random.randint(150, size=20), np.random.randint(4, size=20)] = np.nan\n",
    "\n",
    "nanified_iris_2d[np.isnan(nanified_iris_2d)] = 0\n",
    "np.isnan(nanified_iris_2d).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "39. (L2) **Find the unique values and the count of unique values in iris's species.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Iris-setosa' 50\n",
      "b'Iris-versicolor' 50\n",
      "b'Iris-virginica' 50\n",
      "(array([b'Iris-setosa', b'Iris-versicolor', b'Iris-virginica'],\n",
      "      dtype='|S15'), array([50, 50, 50]))\n"
     ]
    }
   ],
   "source": [
    "# Iterate manually\n",
    "np.unique(species)\n",
    "for value in np.unique(species):\n",
    "    print(value, species.count(value))\n",
    "\n",
    "# Using the unique.return_counts parameter\n",
    "print(\n",
    "    np.unique(species, return_counts=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "40. (L2) **Bin the petal length (3rd) column of iris_2d to form a text array, such that if petal length is:**\n",
    "\n",
    "* Less than 3 --> 'small'\n",
    "* 3-5 --> 'medium'\n",
    "* '>=5 --> 'large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'small', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'large', 'medium', 'medium', 'medium', 'medium', 'medium', 'large', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'medium', 'large', 'large', 'large', 'large', 'large', 'large', 'medium', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'medium', 'large', 'medium', 'large', 'large', 'medium', 'medium', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'medium', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'large', 'large']\n"
     ]
    }
   ],
   "source": [
    "bins = [0.0, 3.0, 5.0]\n",
    "bins_labels = ['small', 'medium', 'large']\n",
    "petallength_put_in_bins = np.digitize(petallength, bins)\n",
    "petallength_categories = [\n",
    "    bins_labels[bin_number-1]\n",
    "    for bin_number in petallength_put_in_bins\n",
    "]\n",
    "print(petallength_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41. (L2) **Create a new column for volume in iris_2d, where volume is `(pi x petallength x sepal_length^2)/3`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.10000000e+00, 3.50000000e+00, 1.40000000e+00, 2.00000000e-01,\n",
       "        5.71989774e+01],\n",
       "       [4.90000000e+00, 3.00000000e+00, 1.40000000e+00, 2.00000000e-01,\n",
       "        5.28007477e+01],\n",
       "       [4.70000000e+00, 3.20000000e+00, 1.30000000e+00, 2.00000000e-01,\n",
       "        4.51085581e+01],\n",
       "       [4.60000000e+00, 3.10000000e+00, 1.50000000e+00, 2.00000000e-01,\n",
       "        4.98570754e+01],\n",
       "       [5.00000000e+00, 3.60000000e+00, 1.40000000e+00, 2.00000000e-01,\n",
       "        5.49778714e+01],\n",
       "       [5.40000000e+00, 3.90000000e+00, 1.70000000e+00, 4.00000000e-01,\n",
       "        7.78675155e+01],\n",
       "       [4.60000000e+00, 3.40000000e+00, 1.40000000e+00, 3.00000000e-01,\n",
       "        4.65332704e+01],\n",
       "       [5.00000000e+00, 3.40000000e+00, 1.50000000e+00, 2.00000000e-01,\n",
       "        5.89048623e+01],\n",
       "       [4.40000000e+00, 2.90000000e+00, 1.40000000e+00, 2.00000000e-01,\n",
       "        4.25748636e+01],\n",
       "       [4.90000000e+00, 3.10000000e+00, 1.50000000e+00, 1.00000000e-01,\n",
       "        5.65722297e+01],\n",
       "       [5.40000000e+00, 3.70000000e+00, 1.50000000e+00, 2.00000000e-01,\n",
       "        6.87066313e+01],\n",
       "       [4.80000000e+00, 3.40000000e+00, 1.60000000e+00, 2.00000000e-01,\n",
       "        5.79058358e+01],\n",
       "       [4.80000000e+00, 3.00000000e+00, 1.40000000e+00, 1.00000000e-01,\n",
       "        5.06676063e+01],\n",
       "       [4.30000000e+00, 3.00000000e+00, 1.10000000e+00, 1.00000000e-01,\n",
       "        3.19484265e+01],\n",
       "       [5.80000000e+00, 4.00000000e+00, 1.20000000e+00, 2.00000000e-01,\n",
       "        6.34099061e+01],\n",
       "       [5.70000000e+00, 4.40000000e+00, 1.50000000e+00, 4.00000000e-01,\n",
       "        7.65527590e+01],\n",
       "       [5.40000000e+00, 3.90000000e+00, 1.30000000e+00, 4.00000000e-01,\n",
       "        5.95457472e+01],\n",
       "       [5.10000000e+00, 3.50000000e+00, 1.40000000e+00, 3.00000000e-01,\n",
       "        5.71989774e+01],\n",
       "       [5.70000000e+00, 3.80000000e+00, 1.70000000e+00, 3.00000000e-01,\n",
       "        8.67597935e+01],\n",
       "       [5.10000000e+00, 3.80000000e+00, 1.50000000e+00, 3.00000000e-01,\n",
       "        6.12846187e+01],\n",
       "       [5.40000000e+00, 3.40000000e+00, 1.70000000e+00, 2.00000000e-01,\n",
       "        7.78675155e+01],\n",
       "       [5.10000000e+00, 3.70000000e+00, 1.50000000e+00, 4.00000000e-01,\n",
       "        6.12846187e+01],\n",
       "       [4.60000000e+00, 3.60000000e+00, 1.00000000e+00, 2.00000000e-01,\n",
       "        3.32380503e+01],\n",
       "       [5.10000000e+00, 3.30000000e+00, 1.70000000e+00, 5.00000000e-01,\n",
       "        6.94559012e+01],\n",
       "       [4.80000000e+00, 3.40000000e+00, 1.90000000e+00, 2.00000000e-01,\n",
       "        6.87631800e+01],\n",
       "       [5.00000000e+00, 3.00000000e+00, 1.60000000e+00, 2.00000000e-01,\n",
       "        6.28318531e+01],\n",
       "       [5.00000000e+00, 3.40000000e+00, 1.60000000e+00, 4.00000000e-01,\n",
       "        6.28318531e+01],\n",
       "       [5.20000000e+00, 3.50000000e+00, 1.50000000e+00, 2.00000000e-01,\n",
       "        6.37114990e+01],\n",
       "       [5.20000000e+00, 3.40000000e+00, 1.40000000e+00, 2.00000000e-01,\n",
       "        5.94640657e+01],\n",
       "       [4.70000000e+00, 3.20000000e+00, 1.60000000e+00, 2.00000000e-01,\n",
       "        5.55182254e+01],\n",
       "       [4.80000000e+00, 3.10000000e+00, 1.60000000e+00, 2.00000000e-01,\n",
       "        5.79058358e+01],\n",
       "       [5.40000000e+00, 3.40000000e+00, 1.50000000e+00, 4.00000000e-01,\n",
       "        6.87066313e+01],\n",
       "       [5.20000000e+00, 4.10000000e+00, 1.50000000e+00, 1.00000000e-01,\n",
       "        6.37114990e+01],\n",
       "       [5.50000000e+00, 4.20000000e+00, 1.40000000e+00, 2.00000000e-01,\n",
       "        6.65232244e+01],\n",
       "       [4.90000000e+00, 3.10000000e+00, 1.50000000e+00, 1.00000000e-01,\n",
       "        5.65722297e+01],\n",
       "       [5.00000000e+00, 3.20000000e+00, 1.20000000e+00, 2.00000000e-01,\n",
       "        4.71238898e+01],\n",
       "       [5.50000000e+00, 3.50000000e+00, 1.30000000e+00, 2.00000000e-01,\n",
       "        6.17715656e+01],\n",
       "       [4.90000000e+00, 3.10000000e+00, 1.50000000e+00, 1.00000000e-01,\n",
       "        5.65722297e+01],\n",
       "       [4.40000000e+00, 3.00000000e+00, 1.30000000e+00, 2.00000000e-01,\n",
       "        3.95338020e+01],\n",
       "       [5.10000000e+00, 3.40000000e+00, 1.50000000e+00, 2.00000000e-01,\n",
       "        6.12846187e+01],\n",
       "       [5.00000000e+00, 3.50000000e+00, 1.30000000e+00, 3.00000000e-01,\n",
       "        5.10508806e+01],\n",
       "       [4.50000000e+00, 2.30000000e+00, 1.30000000e+00, 3.00000000e-01,\n",
       "        4.13512133e+01],\n",
       "       [4.40000000e+00, 3.20000000e+00, 1.30000000e+00, 2.00000000e-01,\n",
       "        3.95338020e+01],\n",
       "       [5.00000000e+00, 3.50000000e+00, 1.60000000e+00, 6.00000000e-01,\n",
       "        6.28318531e+01],\n",
       "       [5.10000000e+00, 3.80000000e+00, 1.90000000e+00, 4.00000000e-01,\n",
       "        7.76271837e+01],\n",
       "       [4.80000000e+00, 3.00000000e+00, 1.40000000e+00, 3.00000000e-01,\n",
       "        5.06676063e+01],\n",
       "       [5.10000000e+00, 3.80000000e+00, 1.60000000e+00, 2.00000000e-01,\n",
       "        6.53702599e+01],\n",
       "       [4.60000000e+00, 3.20000000e+00, 1.40000000e+00, 2.00000000e-01,\n",
       "        4.65332704e+01],\n",
       "       [5.30000000e+00, 3.70000000e+00, 1.50000000e+00, 2.00000000e-01,\n",
       "        6.61855032e+01],\n",
       "       [5.00000000e+00, 3.30000000e+00, 1.40000000e+00, 2.00000000e-01,\n",
       "        5.49778714e+01],\n",
       "       [7.00000000e+00, 3.20000000e+00, 4.70000000e+00, 1.40000000e+00,\n",
       "        3.61754394e+02],\n",
       "       [6.40000000e+00, 3.20000000e+00, 4.50000000e+00, 1.50000000e+00,\n",
       "        2.89529179e+02],\n",
       "       [6.90000000e+00, 3.10000000e+00, 4.90000000e+00, 1.50000000e+00,\n",
       "        3.66449504e+02],\n",
       "       [5.50000000e+00, 2.30000000e+00, 4.00000000e+00, 1.30000000e+00,\n",
       "        1.90066356e+02],\n",
       "       [6.50000000e+00, 2.80000000e+00, 4.60000000e+00, 1.50000000e+00,\n",
       "        3.05284266e+02],\n",
       "       [5.70000000e+00, 2.80000000e+00, 4.50000000e+00, 1.30000000e+00,\n",
       "        2.29658277e+02],\n",
       "       [6.30000000e+00, 3.30000000e+00, 4.70000000e+00, 1.60000000e+00,\n",
       "        2.93021059e+02],\n",
       "       [4.90000000e+00, 2.40000000e+00, 3.30000000e+00, 1.00000000e+00,\n",
       "        1.24458905e+02],\n",
       "       [6.60000000e+00, 2.90000000e+00, 4.60000000e+00, 1.30000000e+00,\n",
       "        3.14749885e+02],\n",
       "       [5.20000000e+00, 2.70000000e+00, 3.90000000e+00, 1.40000000e+00,\n",
       "        1.65649897e+02],\n",
       "       [5.00000000e+00, 2.00000000e+00, 3.50000000e+00, 1.00000000e+00,\n",
       "        1.37444679e+02],\n",
       "       [5.90000000e+00, 3.00000000e+00, 4.20000000e+00, 1.50000000e+00,\n",
       "        2.29653565e+02],\n",
       "       [6.00000000e+00, 2.20000000e+00, 4.00000000e+00, 1.00000000e+00,\n",
       "        2.26194671e+02],\n",
       "       [6.10000000e+00, 2.90000000e+00, 4.70000000e+00, 1.40000000e+00,\n",
       "        2.74711857e+02],\n",
       "       [5.60000000e+00, 2.90000000e+00, 3.60000000e+00, 1.30000000e+00,\n",
       "        1.77336622e+02],\n",
       "       [6.70000000e+00, 3.10000000e+00, 4.40000000e+00, 1.40000000e+00,\n",
       "        3.10257407e+02],\n",
       "       [5.60000000e+00, 3.00000000e+00, 4.50000000e+00, 1.50000000e+00,\n",
       "        2.21670778e+02],\n",
       "       [5.80000000e+00, 2.70000000e+00, 4.10000000e+00, 1.00000000e+00,\n",
       "        2.16650513e+02],\n",
       "       [6.20000000e+00, 2.20000000e+00, 4.50000000e+00, 1.50000000e+00,\n",
       "        2.71716349e+02],\n",
       "       [5.60000000e+00, 2.50000000e+00, 3.90000000e+00, 1.10000000e+00,\n",
       "        1.92114674e+02],\n",
       "       [5.90000000e+00, 3.20000000e+00, 4.80000000e+00, 1.80000000e+00,\n",
       "        2.62461217e+02],\n",
       "       [6.10000000e+00, 2.80000000e+00, 4.00000000e+00, 1.30000000e+00,\n",
       "        2.33797325e+02],\n",
       "       [6.30000000e+00, 2.50000000e+00, 4.90000000e+00, 1.50000000e+00,\n",
       "        3.05490040e+02],\n",
       "       [6.10000000e+00, 2.80000000e+00, 4.70000000e+00, 1.20000000e+00,\n",
       "        2.74711857e+02],\n",
       "       [6.40000000e+00, 2.90000000e+00, 4.30000000e+00, 1.30000000e+00,\n",
       "        2.76661215e+02],\n",
       "       [6.60000000e+00, 3.00000000e+00, 4.40000000e+00, 1.40000000e+00,\n",
       "        3.01065107e+02],\n",
       "       [6.80000000e+00, 2.80000000e+00, 4.80000000e+00, 1.40000000e+00,\n",
       "        3.48641386e+02],\n",
       "       [6.70000000e+00, 3.00000000e+00, 5.00000000e+00, 1.70000000e+00,\n",
       "        3.52565236e+02],\n",
       "       [6.00000000e+00, 2.90000000e+00, 4.50000000e+00, 1.50000000e+00,\n",
       "        2.54469005e+02],\n",
       "       [5.70000000e+00, 2.60000000e+00, 3.50000000e+00, 1.00000000e+00,\n",
       "        1.78623104e+02],\n",
       "       [5.50000000e+00, 2.40000000e+00, 3.80000000e+00, 1.10000000e+00,\n",
       "        1.80563038e+02],\n",
       "       [5.50000000e+00, 2.40000000e+00, 3.70000000e+00, 1.00000000e+00,\n",
       "        1.75811379e+02],\n",
       "       [5.80000000e+00, 2.70000000e+00, 3.90000000e+00, 1.20000000e+00,\n",
       "        2.06082195e+02],\n",
       "       [6.00000000e+00, 2.70000000e+00, 5.10000000e+00, 1.60000000e+00,\n",
       "        2.88398206e+02],\n",
       "       [5.40000000e+00, 3.00000000e+00, 4.50000000e+00, 1.50000000e+00,\n",
       "        2.06119894e+02],\n",
       "       [6.00000000e+00, 3.40000000e+00, 4.50000000e+00, 1.60000000e+00,\n",
       "        2.54469005e+02],\n",
       "       [6.70000000e+00, 3.10000000e+00, 4.70000000e+00, 1.50000000e+00,\n",
       "        3.31411321e+02],\n",
       "       [6.30000000e+00, 2.30000000e+00, 4.40000000e+00, 1.30000000e+00,\n",
       "        2.74317587e+02],\n",
       "       [5.60000000e+00, 3.00000000e+00, 4.10000000e+00, 1.30000000e+00,\n",
       "        2.01966709e+02],\n",
       "       [5.50000000e+00, 2.50000000e+00, 4.00000000e+00, 1.30000000e+00,\n",
       "        1.90066356e+02],\n",
       "       [5.50000000e+00, 2.60000000e+00, 4.40000000e+00, 1.20000000e+00,\n",
       "        2.09072991e+02],\n",
       "       [6.10000000e+00, 3.00000000e+00, 4.60000000e+00, 1.40000000e+00,\n",
       "        2.68866924e+02],\n",
       "       [5.80000000e+00, 2.60000000e+00, 4.00000000e+00, 1.20000000e+00,\n",
       "        2.11366354e+02],\n",
       "       [5.00000000e+00, 2.30000000e+00, 3.30000000e+00, 1.00000000e+00,\n",
       "        1.29590697e+02],\n",
       "       [5.60000000e+00, 2.70000000e+00, 4.20000000e+00, 1.30000000e+00,\n",
       "        2.06892726e+02],\n",
       "       [5.70000000e+00, 3.00000000e+00, 4.20000000e+00, 1.20000000e+00,\n",
       "        2.14347725e+02],\n",
       "       [5.70000000e+00, 2.90000000e+00, 4.20000000e+00, 1.30000000e+00,\n",
       "        2.14347725e+02],\n",
       "       [6.20000000e+00, 2.90000000e+00, 4.30000000e+00, 1.30000000e+00,\n",
       "        2.59640066e+02],\n",
       "       [5.10000000e+00, 2.50000000e+00, 3.00000000e+00, 1.10000000e+00,\n",
       "        1.22569237e+02],\n",
       "       [5.70000000e+00, 2.80000000e+00, 4.10000000e+00, 1.30000000e+00,\n",
       "        2.09244208e+02],\n",
       "       [6.30000000e+00, 3.30000000e+00, 6.00000000e+00, 2.50000000e+00,\n",
       "        3.74069437e+02],\n",
       "       [5.80000000e+00, 2.70000000e+00, 5.10000000e+00, 1.90000000e+00,\n",
       "        2.69492101e+02],\n",
       "       [7.10000000e+00, 3.00000000e+00, 5.90000000e+00, 2.10000000e+00,\n",
       "        4.67184673e+02],\n",
       "       [6.30000000e+00, 2.90000000e+00, 5.60000000e+00, 1.80000000e+00,\n",
       "        3.49131475e+02],\n",
       "       [6.50000000e+00, 3.00000000e+00, 5.80000000e+00, 2.20000000e+00,\n",
       "        3.84923640e+02],\n",
       "       [7.60000000e+00, 3.00000000e+00, 6.60000000e+00, 2.10000000e+00,\n",
       "        5.98812693e+02],\n",
       "       [4.90000000e+00, 2.50000000e+00, 4.50000000e+00, 1.70000000e+00,\n",
       "        1.69716689e+02],\n",
       "       [7.30000000e+00, 2.90000000e+00, 6.30000000e+00, 1.80000000e+00,\n",
       "        5.27358738e+02],\n",
       "       [6.70000000e+00, 2.50000000e+00, 5.80000000e+00, 1.80000000e+00,\n",
       "        4.08975673e+02],\n",
       "       [7.20000000e+00, 3.60000000e+00, 6.10000000e+00, 2.50000000e+00,\n",
       "        4.96723498e+02],\n",
       "       [6.50000000e+00, 3.20000000e+00, 5.10000000e+00, 2.00000000e+00,\n",
       "        3.38467339e+02],\n",
       "       [6.40000000e+00, 2.70000000e+00, 5.30000000e+00, 1.90000000e+00,\n",
       "        3.41001033e+02],\n",
       "       [6.80000000e+00, 3.00000000e+00, 5.50000000e+00, 2.10000000e+00,\n",
       "        3.99484922e+02],\n",
       "       [5.70000000e+00, 2.50000000e+00, 5.00000000e+00, 2.00000000e+00,\n",
       "        2.55175863e+02],\n",
       "       [5.80000000e+00, 2.80000000e+00, 5.10000000e+00, 2.40000000e+00,\n",
       "        2.69492101e+02],\n",
       "       [6.40000000e+00, 3.20000000e+00, 5.30000000e+00, 2.30000000e+00,\n",
       "        3.41001033e+02],\n",
       "       [6.50000000e+00, 3.00000000e+00, 5.50000000e+00, 1.80000000e+00,\n",
       "        3.65013796e+02],\n",
       "       [7.70000000e+00, 3.80000000e+00, 6.70000000e+00, 2.20000000e+00,\n",
       "        6.23987845e+02],\n",
       "       [7.70000000e+00, 2.60000000e+00, 6.90000000e+00, 2.30000000e+00,\n",
       "        6.42614348e+02],\n",
       "       [6.00000000e+00, 2.20000000e+00, 5.00000000e+00, 1.50000000e+00,\n",
       "        2.82743339e+02],\n",
       "       [6.90000000e+00, 3.20000000e+00, 5.70000000e+00, 2.30000000e+00,\n",
       "        4.26277995e+02],\n",
       "       [5.60000000e+00, 2.80000000e+00, 4.90000000e+00, 2.00000000e+00,\n",
       "        2.41374847e+02],\n",
       "       [7.70000000e+00, 2.80000000e+00, 6.70000000e+00, 2.00000000e+00,\n",
       "        6.23987845e+02],\n",
       "       [6.30000000e+00, 2.70000000e+00, 4.90000000e+00, 1.80000000e+00,\n",
       "        3.05490040e+02],\n",
       "       [6.70000000e+00, 3.30000000e+00, 5.70000000e+00, 2.10000000e+00,\n",
       "        4.01924369e+02],\n",
       "       [7.20000000e+00, 3.20000000e+00, 6.00000000e+00, 1.80000000e+00,\n",
       "        4.88580489e+02],\n",
       "       [6.20000000e+00, 2.80000000e+00, 4.80000000e+00, 1.80000000e+00,\n",
       "        2.89830772e+02],\n",
       "       [6.10000000e+00, 3.00000000e+00, 4.90000000e+00, 1.80000000e+00,\n",
       "        2.86401723e+02],\n",
       "       [6.40000000e+00, 2.80000000e+00, 5.60000000e+00, 2.10000000e+00,\n",
       "        3.60302978e+02],\n",
       "       [7.20000000e+00, 3.00000000e+00, 5.80000000e+00, 1.60000000e+00,\n",
       "        4.72294473e+02],\n",
       "       [7.40000000e+00, 2.80000000e+00, 6.10000000e+00, 1.90000000e+00,\n",
       "        5.24702522e+02],\n",
       "       [7.90000000e+00, 3.80000000e+00, 6.40000000e+00, 2.00000000e+00,\n",
       "        6.27413752e+02],\n",
       "       [6.40000000e+00, 2.80000000e+00, 5.60000000e+00, 2.20000000e+00,\n",
       "        3.60302978e+02],\n",
       "       [6.30000000e+00, 2.80000000e+00, 5.10000000e+00, 1.50000000e+00,\n",
       "        3.17959022e+02],\n",
       "       [6.10000000e+00, 2.60000000e+00, 5.60000000e+00, 1.40000000e+00,\n",
       "        3.27316255e+02],\n",
       "       [7.70000000e+00, 3.00000000e+00, 6.10000000e+00, 2.30000000e+00,\n",
       "        5.68108337e+02],\n",
       "       [6.30000000e+00, 3.40000000e+00, 5.60000000e+00, 2.40000000e+00,\n",
       "        3.49131475e+02],\n",
       "       [6.40000000e+00, 3.10000000e+00, 5.50000000e+00, 1.80000000e+00,\n",
       "        3.53868997e+02],\n",
       "       [6.00000000e+00, 3.00000000e+00, 4.80000000e+00, 1.80000000e+00,\n",
       "        2.71433605e+02],\n",
       "       [6.90000000e+00, 3.10000000e+00, 5.40000000e+00, 2.10000000e+00,\n",
       "        4.03842311e+02],\n",
       "       [6.70000000e+00, 3.10000000e+00, 5.60000000e+00, 2.40000000e+00,\n",
       "        3.94873064e+02],\n",
       "       [6.90000000e+00, 3.10000000e+00, 5.10000000e+00, 2.30000000e+00,\n",
       "        3.81406627e+02],\n",
       "       [5.80000000e+00, 2.70000000e+00, 5.10000000e+00, 1.90000000e+00,\n",
       "        2.69492101e+02],\n",
       "       [6.80000000e+00, 3.20000000e+00, 5.90000000e+00, 2.30000000e+00,\n",
       "        4.28538371e+02],\n",
       "       [6.70000000e+00, 3.30000000e+00, 5.70000000e+00, 2.50000000e+00,\n",
       "        4.01924369e+02],\n",
       "       [6.70000000e+00, 3.00000000e+00, 5.20000000e+00, 2.30000000e+00,\n",
       "        3.66667845e+02],\n",
       "       [6.30000000e+00, 2.50000000e+00, 5.00000000e+00, 1.90000000e+00,\n",
       "        3.11724531e+02],\n",
       "       [6.50000000e+00, 3.00000000e+00, 5.20000000e+00, 2.00000000e+00,\n",
       "        3.45103953e+02],\n",
       "       [6.20000000e+00, 3.40000000e+00, 5.40000000e+00, 2.30000000e+00,\n",
       "        3.26059618e+02],\n",
       "       [5.90000000e+00, 3.00000000e+00, 5.10000000e+00, 1.80000000e+00,\n",
       "        2.78865043e+02]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.column_stack(\n",
    "    [\n",
    "        iris_2d,  # Old array\n",
    "        (np.pi * petallength * sepallength ** 2) / 2  # New array with volumes - calculated on the fly\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "42. (L3) **Randomly sample iris's species such that setose is twice the number of versicolor and virginica.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([b'Iris-setosa', b'Iris-versicolor', b'Iris-virginica'],\n",
       "       dtype='|S15'),\n",
       " array([47, 28, 25]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_map = {\n",
    "    b'Iris-setosa': 0.5,\n",
    "    b'Iris-versicolor': 0.25,\n",
    "    b'Iris-virginica': 0.25\n",
    "}\n",
    "sampling_probabilities = np.array([\n",
    "    probabilities_map.get(name)\n",
    "    for name in species\n",
    "])\n",
    "sampling_distribution = sampling_probabilities / sum(sampling_probabilities)\n",
    "sample = np.random.choice(species, size=100, p=sampling_distribution)\n",
    "np.unique(sample, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "43. (L3) **What is the value of second longest petallength of species setosa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'1.7'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(  # Remove repetitions to find the value itself not what is in the second to last POSITION\n",
    "    np.sort([  # Sort ascending\n",
    "        iris_dataset_row[2]\n",
    "        for iris_dataset_row in iris_dataset\n",
    "        if iris_dataset_row[4]  == b'Iris-setosa'\n",
    "    ]\n",
    "    )\n",
    ")[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "44. (L2) **Sort the iris dataset based on sepallength column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'4.3' b'3.0' b'1.1' b'0.1' b'Iris-setosa']\n",
      " [b'4.4' b'3.2' b'1.3' b'0.2' b'Iris-setosa']\n",
      " [b'4.4' b'3.0' b'1.3' b'0.2' b'Iris-setosa']\n",
      " [b'4.4' b'2.9' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'4.5' b'2.3' b'1.3' b'0.3' b'Iris-setosa']\n",
      " [b'4.6' b'3.6' b'1.0' b'0.2' b'Iris-setosa']\n",
      " [b'4.6' b'3.1' b'1.5' b'0.2' b'Iris-setosa']\n",
      " [b'4.6' b'3.4' b'1.4' b'0.3' b'Iris-setosa']\n",
      " [b'4.6' b'3.2' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'4.7' b'3.2' b'1.3' b'0.2' b'Iris-setosa']\n",
      " [b'4.7' b'3.2' b'1.6' b'0.2' b'Iris-setosa']\n",
      " [b'4.8' b'3.0' b'1.4' b'0.1' b'Iris-setosa']\n",
      " [b'4.8' b'3.0' b'1.4' b'0.3' b'Iris-setosa']\n",
      " [b'4.8' b'3.4' b'1.9' b'0.2' b'Iris-setosa']\n",
      " [b'4.8' b'3.4' b'1.6' b'0.2' b'Iris-setosa']\n",
      " [b'4.8' b'3.1' b'1.6' b'0.2' b'Iris-setosa']\n",
      " [b'4.9' b'2.4' b'3.3' b'1.0' b'Iris-versicolor']\n",
      " [b'4.9' b'2.5' b'4.5' b'1.7' b'Iris-virginica']\n",
      " [b'4.9' b'3.1' b'1.5' b'0.1' b'Iris-setosa']\n",
      " [b'4.9' b'3.1' b'1.5' b'0.1' b'Iris-setosa']\n",
      " [b'4.9' b'3.1' b'1.5' b'0.1' b'Iris-setosa']\n",
      " [b'4.9' b'3.0' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'5.0' b'3.5' b'1.3' b'0.3' b'Iris-setosa']\n",
      " [b'5.0' b'3.4' b'1.6' b'0.4' b'Iris-setosa']\n",
      " [b'5.0' b'3.3' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'5.0' b'3.2' b'1.2' b'0.2' b'Iris-setosa']\n",
      " [b'5.0' b'3.5' b'1.6' b'0.6' b'Iris-setosa']\n",
      " [b'5.0' b'2.0' b'3.5' b'1.0' b'Iris-versicolor']\n",
      " [b'5.0' b'3.4' b'1.5' b'0.2' b'Iris-setosa']\n",
      " [b'5.0' b'2.3' b'3.3' b'1.0' b'Iris-versicolor']\n",
      " [b'5.0' b'3.6' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'5.0' b'3.0' b'1.6' b'0.2' b'Iris-setosa']\n",
      " [b'5.1' b'3.8' b'1.9' b'0.4' b'Iris-setosa']\n",
      " [b'5.1' b'3.8' b'1.6' b'0.2' b'Iris-setosa']\n",
      " [b'5.1' b'2.5' b'3.0' b'1.1' b'Iris-versicolor']\n",
      " [b'5.1' b'3.5' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'5.1' b'3.4' b'1.5' b'0.2' b'Iris-setosa']\n",
      " [b'5.1' b'3.5' b'1.4' b'0.3' b'Iris-setosa']\n",
      " [b'5.1' b'3.3' b'1.7' b'0.5' b'Iris-setosa']\n",
      " [b'5.1' b'3.7' b'1.5' b'0.4' b'Iris-setosa']\n",
      " [b'5.1' b'3.8' b'1.5' b'0.3' b'Iris-setosa']\n",
      " [b'5.2' b'4.1' b'1.5' b'0.1' b'Iris-setosa']\n",
      " [b'5.2' b'3.4' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'5.2' b'3.5' b'1.5' b'0.2' b'Iris-setosa']\n",
      " [b'5.2' b'2.7' b'3.9' b'1.4' b'Iris-versicolor']\n",
      " [b'5.3' b'3.7' b'1.5' b'0.2' b'Iris-setosa']\n",
      " [b'5.4' b'3.0' b'4.5' b'1.5' b'Iris-versicolor']\n",
      " [b'5.4' b'3.9' b'1.7' b'0.4' b'Iris-setosa']\n",
      " [b'5.4' b'3.4' b'1.7' b'0.2' b'Iris-setosa']\n",
      " [b'5.4' b'3.4' b'1.5' b'0.4' b'Iris-setosa']\n",
      " [b'5.4' b'3.7' b'1.5' b'0.2' b'Iris-setosa']\n",
      " [b'5.4' b'3.9' b'1.3' b'0.4' b'Iris-setosa']\n",
      " [b'5.5' b'3.5' b'1.3' b'0.2' b'Iris-setosa']\n",
      " [b'5.5' b'2.6' b'4.4' b'1.2' b'Iris-versicolor']\n",
      " [b'5.5' b'4.2' b'1.4' b'0.2' b'Iris-setosa']\n",
      " [b'5.5' b'2.3' b'4.0' b'1.3' b'Iris-versicolor']\n",
      " [b'5.5' b'2.4' b'3.7' b'1.0' b'Iris-versicolor']\n",
      " [b'5.5' b'2.4' b'3.8' b'1.1' b'Iris-versicolor']\n",
      " [b'5.5' b'2.5' b'4.0' b'1.3' b'Iris-versicolor']\n",
      " [b'5.6' b'3.0' b'4.1' b'1.3' b'Iris-versicolor']\n",
      " [b'5.6' b'2.8' b'4.9' b'2.0' b'Iris-virginica']\n",
      " [b'5.6' b'3.0' b'4.5' b'1.5' b'Iris-versicolor']\n",
      " [b'5.6' b'2.5' b'3.9' b'1.1' b'Iris-versicolor']\n",
      " [b'5.6' b'2.7' b'4.2' b'1.3' b'Iris-versicolor']\n",
      " [b'5.6' b'2.9' b'3.6' b'1.3' b'Iris-versicolor']\n",
      " [b'5.7' b'2.6' b'3.5' b'1.0' b'Iris-versicolor']\n",
      " [b'5.7' b'2.9' b'4.2' b'1.3' b'Iris-versicolor']\n",
      " [b'5.7' b'2.8' b'4.1' b'1.3' b'Iris-versicolor']\n",
      " [b'5.7' b'4.4' b'1.5' b'0.4' b'Iris-setosa']\n",
      " [b'5.7' b'2.8' b'4.5' b'1.3' b'Iris-versicolor']\n",
      " [b'5.7' b'2.5' b'5.0' b'2.0' b'Iris-virginica']\n",
      " [b'5.7' b'3.8' b'1.7' b'0.3' b'Iris-setosa']\n",
      " [b'5.7' b'3.0' b'4.2' b'1.2' b'Iris-versicolor']\n",
      " [b'5.8' b'2.7' b'4.1' b'1.0' b'Iris-versicolor']\n",
      " [b'5.8' b'4.0' b'1.2' b'0.2' b'Iris-setosa']\n",
      " [b'5.8' b'2.6' b'4.0' b'1.2' b'Iris-versicolor']\n",
      " [b'5.8' b'2.8' b'5.1' b'2.4' b'Iris-virginica']\n",
      " [b'5.8' b'2.7' b'5.1' b'1.9' b'Iris-virginica']\n",
      " [b'5.8' b'2.7' b'3.9' b'1.2' b'Iris-versicolor']\n",
      " [b'5.8' b'2.7' b'5.1' b'1.9' b'Iris-virginica']\n",
      " [b'5.9' b'3.0' b'5.1' b'1.8' b'Iris-virginica']\n",
      " [b'5.9' b'3.0' b'4.2' b'1.5' b'Iris-versicolor']\n",
      " [b'5.9' b'3.2' b'4.8' b'1.8' b'Iris-versicolor']\n",
      " [b'6.0' b'2.9' b'4.5' b'1.5' b'Iris-versicolor']\n",
      " [b'6.0' b'2.7' b'5.1' b'1.6' b'Iris-versicolor']\n",
      " [b'6.0' b'3.0' b'4.8' b'1.8' b'Iris-virginica']\n",
      " [b'6.0' b'3.4' b'4.5' b'1.6' b'Iris-versicolor']\n",
      " [b'6.0' b'2.2' b'4.0' b'1.0' b'Iris-versicolor']\n",
      " [b'6.0' b'2.2' b'5.0' b'1.5' b'Iris-virginica']\n",
      " [b'6.1' b'3.0' b'4.9' b'1.8' b'Iris-virginica']\n",
      " [b'6.1' b'2.6' b'5.6' b'1.4' b'Iris-virginica']\n",
      " [b'6.1' b'2.8' b'4.0' b'1.3' b'Iris-versicolor']\n",
      " [b'6.1' b'2.9' b'4.7' b'1.4' b'Iris-versicolor']\n",
      " [b'6.1' b'2.8' b'4.7' b'1.2' b'Iris-versicolor']\n",
      " [b'6.1' b'3.0' b'4.6' b'1.4' b'Iris-versicolor']\n",
      " [b'6.2' b'2.2' b'4.5' b'1.5' b'Iris-versicolor']\n",
      " [b'6.2' b'2.9' b'4.3' b'1.3' b'Iris-versicolor']\n",
      " [b'6.2' b'3.4' b'5.4' b'2.3' b'Iris-virginica']\n",
      " [b'6.2' b'2.8' b'4.8' b'1.8' b'Iris-virginica']\n",
      " [b'6.3' b'2.5' b'4.9' b'1.5' b'Iris-versicolor']\n",
      " [b'6.3' b'2.7' b'4.9' b'1.8' b'Iris-virginica']\n",
      " [b'6.3' b'2.5' b'5.0' b'1.9' b'Iris-virginica']\n",
      " [b'6.3' b'3.3' b'4.7' b'1.6' b'Iris-versicolor']\n",
      " [b'6.3' b'2.8' b'5.1' b'1.5' b'Iris-virginica']\n",
      " [b'6.3' b'3.3' b'6.0' b'2.5' b'Iris-virginica']\n",
      " [b'6.3' b'2.3' b'4.4' b'1.3' b'Iris-versicolor']\n",
      " [b'6.3' b'3.4' b'5.6' b'2.4' b'Iris-virginica']\n",
      " [b'6.3' b'2.9' b'5.6' b'1.8' b'Iris-virginica']\n",
      " [b'6.4' b'2.8' b'5.6' b'2.2' b'Iris-virginica']\n",
      " [b'6.4' b'2.8' b'5.6' b'2.1' b'Iris-virginica']\n",
      " [b'6.4' b'3.1' b'5.5' b'1.8' b'Iris-virginica']\n",
      " [b'6.4' b'3.2' b'4.5' b'1.5' b'Iris-versicolor']\n",
      " [b'6.4' b'3.2' b'5.3' b'2.3' b'Iris-virginica']\n",
      " [b'6.4' b'2.9' b'4.3' b'1.3' b'Iris-versicolor']\n",
      " [b'6.4' b'2.7' b'5.3' b'1.9' b'Iris-virginica']\n",
      " [b'6.5' b'3.0' b'5.8' b'2.2' b'Iris-virginica']\n",
      " [b'6.5' b'3.0' b'5.5' b'1.8' b'Iris-virginica']\n",
      " [b'6.5' b'3.0' b'5.2' b'2.0' b'Iris-virginica']\n",
      " [b'6.5' b'2.8' b'4.6' b'1.5' b'Iris-versicolor']\n",
      " [b'6.5' b'3.2' b'5.1' b'2.0' b'Iris-virginica']\n",
      " [b'6.6' b'2.9' b'4.6' b'1.3' b'Iris-versicolor']\n",
      " [b'6.6' b'3.0' b'4.4' b'1.4' b'Iris-versicolor']\n",
      " [b'6.7' b'3.1' b'4.7' b'1.5' b'Iris-versicolor']\n",
      " [b'6.7' b'3.1' b'5.6' b'2.4' b'Iris-virginica']\n",
      " [b'6.7' b'2.5' b'5.8' b'1.8' b'Iris-virginica']\n",
      " [b'6.7' b'3.0' b'5.0' b'1.7' b'Iris-versicolor']\n",
      " [b'6.7' b'3.1' b'4.4' b'1.4' b'Iris-versicolor']\n",
      " [b'6.7' b'3.3' b'5.7' b'2.5' b'Iris-virginica']\n",
      " [b'6.7' b'3.0' b'5.2' b'2.3' b'Iris-virginica']\n",
      " [b'6.7' b'3.3' b'5.7' b'2.1' b'Iris-virginica']\n",
      " [b'6.8' b'3.2' b'5.9' b'2.3' b'Iris-virginica']\n",
      " [b'6.8' b'2.8' b'4.8' b'1.4' b'Iris-versicolor']\n",
      " [b'6.8' b'3.0' b'5.5' b'2.1' b'Iris-virginica']\n",
      " [b'6.9' b'3.1' b'5.4' b'2.1' b'Iris-virginica']\n",
      " [b'6.9' b'3.1' b'5.1' b'2.3' b'Iris-virginica']\n",
      " [b'6.9' b'3.1' b'4.9' b'1.5' b'Iris-versicolor']\n",
      " [b'6.9' b'3.2' b'5.7' b'2.3' b'Iris-virginica']\n",
      " [b'7.0' b'3.2' b'4.7' b'1.4' b'Iris-versicolor']\n",
      " [b'7.1' b'3.0' b'5.9' b'2.1' b'Iris-virginica']\n",
      " [b'7.2' b'3.0' b'5.8' b'1.6' b'Iris-virginica']\n",
      " [b'7.2' b'3.2' b'6.0' b'1.8' b'Iris-virginica']\n",
      " [b'7.2' b'3.6' b'6.1' b'2.5' b'Iris-virginica']\n",
      " [b'7.3' b'2.9' b'6.3' b'1.8' b'Iris-virginica']\n",
      " [b'7.4' b'2.8' b'6.1' b'1.9' b'Iris-virginica']\n",
      " [b'7.6' b'3.0' b'6.6' b'2.1' b'Iris-virginica']\n",
      " [b'7.7' b'2.8' b'6.7' b'2.0' b'Iris-virginica']\n",
      " [b'7.7' b'2.6' b'6.9' b'2.3' b'Iris-virginica']\n",
      " [b'7.7' b'3.8' b'6.7' b'2.2' b'Iris-virginica']\n",
      " [b'7.7' b'3.0' b'6.1' b'2.3' b'Iris-virginica']\n",
      " [b'7.9' b'3.8' b'6.4' b'2.0' b'Iris-virginica']]\n"
     ]
    }
   ],
   "source": [
    "sorted_sepallength_indices = iris_2d[:,0].argsort()\n",
    "sorted_iris_array = iris_dataset[sorted_sepallength_indices]\n",
    "print(sorted_iris_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "45. (L1) **Find the most frequent value of petal length (3rd column) in iris dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'1.5'\n"
     ]
    }
   ],
   "source": [
    "values, counts = np.unique(iris_dataset[:,2], return_counts=True)\n",
    "maximum_unique_value_index = counts.argmax()\n",
    "print(values[maximum_unique_value_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "46. (L2) **Find the position of the first occurrence of a value greater than 1.0 in petalwidth 4th column of iris dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "petalwidth = iris_2d[:, 3]\n",
    "np.argwhere(petalwidth > 1.0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "47. (L2) **From the array `a`, replace all values greater than 30 to 30 and less than 10 to 10.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27.62684215 14.64009987 21.80136195 30.         10.         10.\n",
      " 30.         30.         10.         29.17957314 30.         11.25090398\n",
      " 10.08108276 10.         11.76517714 30.         30.         10.\n",
      " 30.         14.42961361]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "a = np.random.uniform(1,50, 20)\n",
    "a[a > 30] = 30\n",
    "a[a < 10] = 10\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "48. (L2) **Get the positions of top 5 maximum values in a given array `a`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 13,  5,  8, 17])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs\n",
    "\n",
    "np.random.seed(100)\n",
    "a = np.random.uniform(1,50, 20)\n",
    "\n",
    "np.argsort(a)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "49. (L4) **Compute the counts of unique values row-wise.**\n",
    "\n",
    "**NOTE**: The solution provided on the site seems to be either wrong or made for a different version of the dataset. The counts presented here do not show how many time each value appears in each row. I will provide a solution that does that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  9  4  8  8  1  5  3  6  3]\n",
      " [ 3  3  2  1  9  5  1 10  7  3]\n",
      " [ 5  2  6  4  5  5  4  8  2  2]\n",
      " [ 8  8  1  3 10 10  4  3  6  9]\n",
      " [ 2  1  8  7  3  1  9  3  6  2]\n",
      " [ 9  2  6  5  3  9  4  6  1 10]]\n",
      "[[2 2 1 2 2 1 1 2 1 2]\n",
      " [3 3 1 2 1 1 2 1 1 3]\n",
      " [3 3 1 2 3 3 2 1 3 3]\n",
      " [2 2 1 2 2 2 1 2 1 1]\n",
      " [2 2 1 1 2 2 1 2 1 2]\n",
      " [2 1 2 1 1 2 1 2 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "np.random.seed(100)\n",
    "arr = np.random.randint(1,11,size=(6, 10))\n",
    "\n",
    "counts_arr = arr.copy()\n",
    "for row in range(0, arr.shape[0]):\n",
    "    values, counts = np.unique(arr[row], return_counts=True)\n",
    "    counts_map = {\n",
    "        values[i]: counts[i]\n",
    "        for i in range(0, len(values))\n",
    "    }\n",
    "    for column in range(arr.shape[1]):\n",
    "        counts_arr[row, column] = counts_map[arr[row, column]]\n",
    "print(arr)\n",
    "print(counts_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50. (L2) **Convert `array_of_arrays` into a flat linear 1d array.**\n",
    "\n",
    "Desired output:\n",
    "\n",
    "```python\n",
    "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs\n",
    "\n",
    "arr1 = np.arange(3)\n",
    "arr2 = np.arange(3,7)\n",
    "arr3 = np.arange(7,10)\n",
    "\n",
    "np.hstack([arr1, arr2, arr3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "51. (L2) **Compute the one-hot encodings (dummy binary variables for each unique value in the array)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 2 2 2 1]\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "np.random.seed(101) \n",
    "arr = np.random.randint(1,4, size=6)\n",
    "print(arr)\n",
    "\n",
    "dummy = np.zeros((arr.shape[0], arr.max()))\n",
    "for index in range(0, arr.shape[0]):\n",
    "    dummy[index, arr[index] - 1] = 1\n",
    "print(dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "52. (L3) **Create row numbers grouped by a categorical variable. Use the following sample from iris `species` as input.**\n",
    "\n",
    "Desired output:\n",
    "\n",
    "```python\n",
    "[0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 6, 7]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values :[b'Iris-setosa' b'Iris-versicolor' b'Iris-virginica']\n",
      "\n",
      "Counts: [5 6 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "species_small = np.sort(np.random.choice(species, size=20))\n",
    "species_small\n",
    "\n",
    "values, counts = np.unique(species_small, return_counts=True)\n",
    "print(f'Unique values :{values}\\n')\n",
    "print(f'Counts: {counts}')\n",
    "\n",
    "np.hstack([\n",
    "    np.arange(index)\n",
    "    for index in counts\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "53. (L4) **Create group ids based on a given categorical variable. Use the following sample from iris `species` as input.**\n",
    "\n",
    "Desired output:\n",
    "\n",
    "```python\n",
    "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'Iris-setosa' b'Iris-setosa' b'Iris-setosa' b'Iris-setosa'\n",
      " b'Iris-setosa' b'Iris-setosa' b'Iris-versicolor' b'Iris-versicolor'\n",
      " b'Iris-versicolor' b'Iris-versicolor' b'Iris-versicolor'\n",
      " b'Iris-versicolor' b'Iris-virginica' b'Iris-virginica' b'Iris-virginica'\n",
      " b'Iris-virginica' b'Iris-virginica' b'Iris-virginica' b'Iris-virginica'\n",
      " b'Iris-virginica']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs\n",
    "\n",
    "species_small = np.sort(np.random.choice(species, size=20))\n",
    "unique_groups = np.unique(species_small)\n",
    "print(species_small)\n",
    "\n",
    "[\n",
    "    np.argwhere(unique_groups == species_small[index]).flat[0]\n",
    "    for index in range(0, species_small.shape[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "54. (L2) **Create the ranks for the given numeric array `a`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9  4 15  0 17 16 17  8  9  0]\n",
      "[ 5.  3.  7.  1.  9.  8. 10.  4.  6.  2.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 2, 6, 0, 8, 7, 9, 3, 5, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "np.random.seed(10)\n",
    "a = np.random.randint(20, size=10)\n",
    "print(a)\n",
    "\n",
    "# Manual\n",
    "ranks = np.zeros(a.shape[0])\n",
    "for element_index in range(0, a.shape[0]):\n",
    "    for rank in np.argwhere(np.sort(a) == a[element_index]):\n",
    "        if rank + 1 not in ranks:\n",
    "            ranks[element_index] = rank[0] + 1\n",
    "            break\n",
    "print(ranks)\n",
    "\n",
    "# Double argsort = ranking\n",
    "a.argsort().argsort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "55. (L3) **Create a rank array of the same shape as a given numeric array `a`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 2, 6, 0, 8],\n",
       "       [7, 9, 3, 5, 1]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "np.random.seed(10)\n",
    "a = np.random.randint(20, size=[2,5])\n",
    "\n",
    "a.flatten().argsort().argsort().reshape(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "56. (L2) **Compute the maximum for each row in the given array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 8, 6, 3, 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 8, 6, 3, 9])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "np.random.seed(100)\n",
    "a = np.random.randint(1,10, [5,3])\n",
    "\n",
    "print([\n",
    "    np.max(row)\n",
    "    for row in a\n",
    "])\n",
    "\n",
    "np.amax(a, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "57. (L3) **Compute the min-by-max for each row for given 2d array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44444444, 0.125     , 0.5       , 1.        , 0.11111111])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "np.random.seed(100)\n",
    "a = np.random.randint(1,10, [5,3])\n",
    "\n",
    "np.apply_along_axis(\n",
    "    lambda row: row.min() / row.max(),\n",
    "    axis=1,\n",
    "    arr=a\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "58. (L3) **Find the duplicate entries (2nd occurrence onwards) in the given numpy array and mark them as True. First time occurrences should be False.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True, False, False,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "np.random.seed(100)\n",
    "a = np.random.randint(0, 5, 10)\n",
    "\n",
    "_, indices = np.unique(a, return_index=True)\n",
    "duplicates = np.full(a.shape[0], True)\n",
    "duplicates[indices] = False\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "59. (L3) **Find the mean of a numeric column grouped by a categorical column in a 2D numpy array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Iris-setosa' 3.418\n",
      "b'Iris-versicolor' 2.7700000000000005\n",
      "b'Iris-virginica' 2.974\n"
     ]
    }
   ],
   "source": [
    "COLUMN = 1\n",
    "groups = np.unique(iris_dataset[:, 4])\n",
    "for group_name in groups:\n",
    "    print(\n",
    "        group_name,\n",
    "        np.mean(\n",
    "            iris_dataset[\n",
    "                np.where(iris_dataset[:, 4] == group_name)\n",
    "            ][:, COLUMN].astype(float)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60. (L3) **Import the image from the following URL and convert it to a numpy array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9,  72, 125],\n",
       "       [  9,  72, 125],\n",
       "       [  9,  72, 125],\n",
       "       ...,\n",
       "       [ 15,  51,  77],\n",
       "       [ 12,  48,  74],\n",
       "       [ 11,  45,  72]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "\n",
    "URL = 'https://upload.wikimedia.org/wikipedia/commons/8/8b/Denali_Mt_McKinley.jpg'\n",
    "\n",
    "downloaded_image = Image.open(\n",
    "    io.BytesIO(\n",
    "        requests.get(URL).content\n",
    "    )\n",
    ")\n",
    "np.array(\n",
    "    list(\n",
    "        downloaded_image.getdata()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "61. (L2) **Drop all nan values from a 1D numpy array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 5. 6. 7.]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "a = np.array([1,2,3,np.nan,5,6,7,np.nan])\n",
    "\n",
    "a = a[\n",
    "    np.where(\n",
    "        np.isnan(a) == False\n",
    "    )\n",
    "]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "62. (L3) **Compute the euclidean distance between two arrays a and b.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "\n",
    "a = np.array([1,2,3,4,5])\n",
    "b = np.array([4,5,6,7,8])\n",
    "\n",
    "manual = np.sqrt(\n",
    "    np.sum((b - a)**2)\n",
    ")\n",
    "\n",
    "linalg = np.linalg.norm(a-b)\n",
    "print(manual == linalg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "63. (L3) **Find all the peaks in a 1D numpy array a. Peaks are points surrounded by smaller values on both sides.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 5]\n",
      "[2, 5]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "a = np.array([1, 3, 7, 1, 2, 6, 0, 1])\n",
    "\n",
    "# Dunno about this one, seems to be tailored to specific data\n",
    "dunno = np.where(\n",
    "    np.diff(\n",
    "        np.sign(  # Takes the sign\n",
    "            np.diff(a)\n",
    "        )\n",
    "    ) == 0\n",
    ")[0] + 2  # double differential reduces indices by 2 (due to the i and i+1 pairs)\n",
    "\n",
    "# General approach\n",
    "\n",
    "a_diffs = np.sign(np.diff(np.hstack([a[0], a])))\n",
    "general = [\n",
    "    diff_index\n",
    "    for diff_index in range(len(a_diffs[1:]))\n",
    "    if a_diffs[diff_index] == 1 and a_diffs[diff_index+1] == -1  # Signs of differences: (+1) / [MAX] \\ (-1)\n",
    "]\n",
    "\n",
    "print(dunno)\n",
    "print(general)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "64. (L2) **Subtract the 1d array `b_1d` from the 2d array `a_2d`, such that each item of `b_1d` subtracts from respective row of `a_2d`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2],\n",
       "       [2, 2, 2],\n",
       "       [2, 2, 2]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs\n",
    "\n",
    "a_2d = np.array([[3,3,3],[4,4,4],[5,5,5]])\n",
    "b_1d = np.array([1,2,3])\n",
    "\n",
    "a_2d - b_1d.reshape(b_1d.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "65. (L2) **Find the index of 5th repetition of number 1 in x.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs\n",
    "\n",
    "x = np.array([1, 2, 1, 1, 3, 4, 3, 1, 1, 2, 1, 1, 2])\n",
    "\n",
    "target_number = 1\n",
    "target_occurrence = 5\n",
    "\n",
    "np.argwhere(\n",
    "    x == target_number\n",
    ")[target_occurrence-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "66. (L2) **Convert numpy's datetime64 object to datetime's datetime object.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "dt64 = np.datetime64('2018-02-25 22:10:10')\n",
    "\n",
    "manual = datetime.datetime.fromisoformat(dt64.astype(str))\n",
    "casted = dt64.astype(datetime.datetime)\n",
    "\n",
    "manual == casted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "67. (L3) **Compute the moving average of window size 3, for the given 1D array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 8 3 7 7 0 4 2 5 2]\n",
      "[6.333333333333333, 6.0, 5.666666666666667, 4.666666666666667, 3.6666666666666665, 2.0, 3.6666666666666665]\n",
      "[6.33333333 6.         5.66666667 4.66666667 3.66666667 2.\n",
      " 3.66666667 3.        ]\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "\n",
    "np.random.seed(100)\n",
    "Z = np.random.randint(10, size=10)\n",
    "\n",
    "print(Z)\n",
    "\n",
    "window_size = 3\n",
    "\n",
    "manual = [\n",
    "    np.average(\n",
    "        Z[index:index+window_size]\n",
    "    )\n",
    "    for index in range(0, Z.shape[0]-window_size)\n",
    "]\n",
    "\n",
    "convoluted = np.convolve(\n",
    "    Z,\n",
    "    np.ones(window_size)/window_size,\n",
    "    mode='valid'\n",
    ")\n",
    "print(manual)\n",
    "print(convoluted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "68. (L2) **Create a numpy array of length 10, starting from 5 and has a step of 3 between consecutive numbers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  8, 11, 14, 17, 20, 23, 26, 29, 32])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 5\n",
    "step = 3\n",
    "number_of_elements = 10\n",
    "\n",
    "np.arange(start, start + number_of_elements * step, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "69. (L3) **Given an array of a non-continuous sequence of dates. Make it a continuous sequence of dates, by filling in the missing dates.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2018-02-01', '2018-02-02', '2018-02-03', '2018-02-04',\n",
       "       '2018-02-05', '2018-02-06', '2018-02-07', '2018-02-08',\n",
       "       '2018-02-09', '2018-02-10', '2018-02-11', '2018-02-12',\n",
       "       '2018-02-13', '2018-02-15', '2018-02-17', '2018-02-19',\n",
       "       '2018-02-21', '2018-02-23'], dtype='datetime64[D]')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs\n",
    "\n",
    "dates = np.arange(np.datetime64('2018-02-01'), np.datetime64('2018-02-25'), 2)\n",
    "\n",
    "for index in range(0, dates.shape[0]-1):\n",
    "    missing_dates = np.arange(dates[index], dates[index+1], 1)[1:]\n",
    "    dates = np.insert(\n",
    "        dates,\n",
    "        index+1,\n",
    "        missing_dates\n",
    "    )\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70. (L4) **From the given 1d array `arr`, generate a 2d matrix using strides, with a window length of 4 and strides of 2, like `[[0,1,2,3], [2,3,4,5], [4,5,6,7]..]`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 1, 2, 3]), array([2, 3, 4, 5]), array([4, 5, 6, 7]), array([6, 7, 8, 9]), array([ 8,  9, 10, 11]), array([10, 11, 12, 13])]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "arr = np.arange(15)\n",
    "\n",
    "stride = 2\n",
    "window_size = 4\n",
    "\n",
    "manual = [\n",
    "    arr[jump*stride:jump*stride+window_size]\n",
    "    for jump in range(0, int(arr.shape[0] / stride + 1))\n",
    "    if jump*stride+window_size < arr.shape[0]\n",
    "]\n",
    "print(manual)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
