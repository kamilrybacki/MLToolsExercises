{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 101 Pandas Exercises for Data Analysis\n",
    "\n",
    "*by Selva Prabhakaran*\n",
    "\n",
    "From the website: https://www.machinelearningplus.com/python/101-pandas-exercises-python/\n",
    "\n",
    "*101 python pandas exercises are designed to challenge your logical muscle and to help internalize data manipulation with python’s favorite package for data analysis.*\n",
    "*The questions are of 3 levels of difficulties with L1 being the easiest to L3 being the hardest.*\n",
    "\n",
    "**NOTE**: Again, its 75 not 100, but the exercises are good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (L1) **Import `pandas` and check the version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (L1) **Create a `pandas` series from each of the items below: a list, numpy and a dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Inputs\n",
    "\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "\n",
    "for data in [mylist, myarr, mydict]:\n",
    "    print(pd.Series(data).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (L1) **Convert the series `ser` into a dataframe with its index as another column on the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "ser = pd.Series(mydict)\n",
    "\n",
    "ser.to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (L1) **Combine `ser1` and `ser2` to form a dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "\n",
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser2 = pd.Series(np.arange(26))\n",
    "\n",
    "np.all(\n",
    "    pd.DataFrame([ser1, ser2]).T  # Stacking horizontally and rotating by 90 deg\n",
    "    == pd.concat([ser1, ser2], axis=1)  # Stacking rotated series\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (L1) **Give a name to the series `ser` calling it `my_series`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "\n",
    "ser.name = \"my_series\"\n",
    "\n",
    "ser.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (L2) **From `ser1` remove items present in `ser2`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "\n",
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "# With numpy\n",
    "with_numpy = np.setdiff1d(ser1, ser2)\n",
    "\n",
    "# With pandas\n",
    "with_pandas = ser1[~ser1.isin(ser2)]\n",
    "\n",
    "print(with_numpy)  # Results in ndarray\n",
    "print(with_pandas)  # Results in Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. (L2) **Get the items not common to both series `ser1` and `ser2`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "union = np.union1d(ser1, ser2)\n",
    "intersection = np.intersect1d(ser1, ser2)\n",
    "\n",
    "print(union, intersection)\n",
    "union[~pd.Series(union).isin(intersection)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. (L2) **Compute the minimum, 25th percentile, median, 75th, and maximum of `ser`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series(np.random.normal(10, 5, 25))\n",
    "\n",
    "for method in [pd.Series.max, pd.Series.min, pd.Series.median]:\n",
    "    print(method(ser))\n",
    "print(ser.quantile(0.25))\n",
    "print(ser.quantile(0.75))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. (L2) **Calcualte the frequency counts of each unique item in `ser`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n",
    "\n",
    "# Through numpy\n",
    "with_numpy = np.unique(ser.to_numpy(), return_counts=True)\n",
    "\n",
    "# Through pandas\n",
    "with_pandas = ser.value_counts()\n",
    "\n",
    "print(with_numpy)\n",
    "print(with_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. (L2) **From `ser`, keep the top 2 most frequent items as it is and replace everything else as `Other`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "\n",
    "\n",
    "ser[~ser.isin(ser.value_counts()[:2].index.to_series())] = 'Other'\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. (L2) **Bin the series `ser` into 10 equal deciles and replace the values with the bin name.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series(np.random.random(20))\n",
    "\n",
    "with_cut = pd.cut(\n",
    "    ser,\n",
    "    bins=np.percentile(ser, np.arange(0, 110, 10)),\n",
    "    labels=['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "with_qcut = pd.qcut(\n",
    "    ser,\n",
    "    q=np.arange(0, 1.1, .1),\n",
    "    labels=['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th']\n",
    ")\n",
    "\n",
    "np.all(with_cut == with_qcut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. (L1) **Reshape the series `ser` into a dataframe with 7 rows and 5 columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "\n",
    "pd.DataFrame(\n",
    "    ser.to_numpy().reshape((7,5))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. (L2)  **Find the positions of numbers that are multiples of 3 from `ser`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series(np.random.randint(1, 10, 7))\n",
    "\n",
    "print(ser)\n",
    "np.argwhere(ser.to_numpy() % 3 == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. (L1) **From `ser`, extract the items at positions in list `pos`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "pos = [0, 4, 8, 14, 20]\n",
    "\n",
    "np.all(ser[pos] == ser.take(pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. (L1) **Stack two series vertically and horizontally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))\n",
    "\n",
    "horizontally = pd.concat([ser1, ser2], axis=0)\n",
    "vertically = pd.concat([ser1, ser2], axis=1)\n",
    "print(horizontally, vertically)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. (L2) **Get the positions of items of `ser2` in `ser1` as a list.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])\n",
    "\n",
    "np.argwhere(\n",
    "    ser1.isin(ser2).to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. (L2) **Compute the mean squared error of `truth` and `pred`.**\n",
    "\n",
    "**NOTE**: This question means that we need to calculate the mean squared error between the two series, using the formula:\n",
    "\n",
    "$$MSE = \\dfrac{1}{n} * \\sum \\left(truth - pred\\right)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)\n",
    "\n",
    "np.mean(\n",
    "    (truth-pred)**2  # Squares of errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. (L2) **Convert the first character of each element in `ser` to uppercase.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "\n",
    "ser.apply(str.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. (L2) **Calculate the number of characters in each word in `ser`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "\n",
    "ser.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. (L2) **Compute the difference of differences between consecutive numbers in `ser`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n",
    "\n",
    "ser.diff().diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. (L2) **Convert a series of date-strings to a timeseries**\n",
    "\n",
    "Desired output:\n",
    "\n",
    "```\n",
    "0   2010-01-01 00:00:00\n",
    "1   2011-02-02 00:00:00\n",
    "2   2012-03-03 00:00:00\n",
    "3   2013-04-04 00:00:00\n",
    "4   2014-05-05 00:00:00\n",
    "5   2015-06-06 12:20:00\n",
    "dtype: datetime64[ns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "ser.astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. (L2) **Get the day of month, week number, day of year and day of week from `ser`.**\n",
    "\n",
    "Desired output:\n",
    "\n",
    "```\n",
    "Date:  [1, 2, 3, 4, 5, 6]\n",
    "Week number:  [53, 5, 9, 14, 19, 23]\n",
    "Day num of year:  [1, 33, 63, 94, 125, 157]\n",
    "Day of week:  ['Friday', 'Wednesday', 'Saturday', 'Thursday', 'Monday', 'Saturday']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "# Manual\n",
    "\n",
    "dates = []\n",
    "week_numbers = []\n",
    "day_numbers = []\n",
    "weekdays = []\n",
    "weekday_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Friday']\n",
    "\n",
    "for index, date in enumerate(ser.astype('datetime64[ns]')):\n",
    "    dates.append(index)\n",
    "    week_numbers.append(date.week)\n",
    "    day_numbers.append(date.day_of_year)\n",
    "    weekdays.append(weekday_names[date.weekday()])\n",
    "\n",
    "print('Manual')\n",
    "print(dates)\n",
    "print(week_numbers)\n",
    "print(day_numbers)\n",
    "print(weekdays)\n",
    "\n",
    "# With 'dt' property (incomplete)\n",
    "\n",
    "import dateutil\n",
    "\n",
    "timeseries = ser.map(dateutil.parser.parse)\n",
    "\n",
    "print('\\nThrough API')\n",
    "print(timeseries.dt.day.to_list())\n",
    "#print(timeseries.dt.weekofyear.to_list()) Doesn't work anymore, maybe API changed!\n",
    "print(timeseries.dt.day_of_year.to_list())\n",
    "print(timeseries.dt.weekday.map(lambda weekday_number: weekday_names[weekday_number]).to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. (L2) **Change `ser` to dates that start with 4th of the respective months.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n",
    "\n",
    "import datetime\n",
    "def shift_day(day_string: str) -> datetime.datetime:\n",
    "    return dateutil.parser.parse(f'4th {day_string}')\n",
    "\n",
    "pd.Series(\n",
    "    np.vectorize(shift_day)(ser)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. (L3) **From `ser`, extract words that contain atleast 2 vowels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n",
    "\n",
    "def count_vowels(word: str) -> int:\n",
    "    return len([\n",
    "        letter\n",
    "        for letter in np.array([*word.lower()])\n",
    "        if letter in ['a', 'e', 'i', 'o', 'u']\n",
    "    ])\n",
    "\n",
    "ser[\n",
    "    ser.map(count_vowels) >= 2  # This serves as mask for the ser Series\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25. (L3) **Extract the valid `emails` from the series emails. The regex pattern for valid emails is provided as reference.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
    "\n",
    "import re\n",
    "\n",
    "emails[\n",
    "    emails.map(\n",
    "        lambda input_email: re.compile(pattern).match(input_email)\n",
    "    ).values != None\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26. (L2) **Compute the mean of `weights` of each `fruit`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "\n",
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "\n",
    "fruits_dataframe = pd.DataFrame(\n",
    "    np.vstack([fruit, weights])\n",
    ").T\n",
    "fruits_dataframe.columns = [\"fruit\", \"weight\"]\n",
    "fruits_dataframe.groupby('fruit').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27. (L2) **Compute the euclidean distance between series (points) p and q, without using a packaged formula.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "\n",
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
    "\n",
    "via_dataframe = np.sqrt(\n",
    "    pd.DataFrame([p,q]).T.apply(lambda row: (row[1]-row[0])**2, axis=1).sum(axis=0)\n",
    ")\n",
    "via_norm = np.sqrt(np.sum((q-p)**2))\n",
    "\n",
    "np.isclose(via_dataframe, via_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28. (L3) **Get the positions of peaks (values surrounded by smaller values on both sides) in `ser`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n",
    "\n",
    "# From NumPy exercises\n",
    "a_diffs = np.sign(np.diff(np.hstack([ser[0], ser])))\n",
    "[\n",
    "    diff_index\n",
    "    for diff_index in range(len(a_diffs[1:]))\n",
    "    if a_diffs[diff_index] == 1 and a_diffs[diff_index+1] == -1  # Signs of differences: (+1) / [MAX] \\ (-1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29. (L3) **Replace missing spaces in the string `my_str` with the least frequent character.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "my_str = 'dbc deb abed gade'\n",
    "\n",
    "uniques, counts = np.unique(\n",
    "    pd.Series([*my_str]),\n",
    "    return_counts=True\n",
    ")\n",
    "least_frequent_character = uniques[np.argmin(counts)]\n",
    "\n",
    "my_str.replace(' ', least_frequent_character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30. (L3) **Create a TimeSeries starting `2000-01-01` and 10 weekends (saturdays) after that having random numbers as values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'date': pd.date_range('2020-01-01', periods=10, freq='7D'),\n",
    "    'number': np.random.randint(low=0, high=100, size=10)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31. (L2) **`ser` has missing dates and values. Make all missing dates appear and fill up with value from previous date.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "\n",
    "'''\n",
    "From docs:\n",
    "\n",
    "Series.resample: method for frequency conversion and resampling of time series\n",
    "\n",
    "Here: instead of sampling at random days, we shift the frequency to ONE DAY and then fill missing values with ffill\n",
    "'''\n",
    "ser.resample('D').ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32. (L3) **Compute autocorrelations for the first 10 lags of `ser`. Find out which lag has the largest correlation.**\n",
    "\n",
    "Desired output:\n",
    "\n",
    "```python\n",
    "# values will change due to randomness\n",
    "[0.29999999999999999, -0.11, -0.17000000000000001, 0.46000000000000002, 0.28000000000000003, -0.040000000000000001, -0.37, 0.41999999999999998, 0.47999999999999998, 0.17999999999999999]\n",
    "Lag having highest correlation:  9\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n",
    "\n",
    "autocorrelations = pd.Series([\n",
    "    ser.autocorr(lag)\n",
    "    for lag in range(1,11)\n",
    "])\n",
    "\n",
    "print(autocorrelations.to_list())\n",
    "print(autocorrelations.copy().abs().argmax() + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33. (L2) **Import every 50th row of `boston` dataset as a dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "BOSTON_URL = \"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"\n",
    "\n",
    "pd.DataFrame([\n",
    "    chunk.iloc[0,:]  # This takes first line\n",
    "    for chunk in pd.read_csv(\n",
    "        BOSTON_URL,\n",
    "        chunksize=50  # Of every chunk that is 50 rows long\n",
    "    )\n",
    "]).reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34. (L2) **Import the boston housing dataset, but while importing change the `medv` (median house value) column so that values < 25 becomes `Low` and > 25 becomes `High`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(row: np.generic):\n",
    "    row['medv'] = 'Low' if row['medv'] < 25 else 'High'\n",
    "    return row\n",
    "\n",
    "via_apply = pd.read_csv(BOSTON_URL).apply(categorize, axis=1)\n",
    "via_converters = pd.read_csv(BOSTON_URL, converters={\n",
    "    'medv': lambda median_value: 'Low' if float(median_value) < 25 else 'High'\n",
    "})\n",
    "np.all(via_apply == via_converters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35. (L3) **Create a dataframe with rows as strides from a given series**\n",
    "\n",
    "Desired output:\n",
    "\n",
    "```python\n",
    "array([[ 0,  1,  2,  3],\n",
    "       [ 2,  3,  4,  5],\n",
    "       [ 4,  5,  6,  7],\n",
    "       [ 6,  7,  8,  9],\n",
    "       [ 8,  9, 10, 11],\n",
    "       [10, 11, 12, 13]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "L = pd.Series(range(15))\n",
    "\n",
    "window_width = 4\n",
    "stride_jump = 2\n",
    "\n",
    "pd.DataFrame(\n",
    "np.array(\n",
    "    [\n",
    "        L[stride_jump*stride:(stride_jump*stride+window_width)]\n",
    "        for stride in range(int((len(L)-window_width)/stride_jump) + 1)\n",
    "    ]\n",
    "    ).reshape(\n",
    "        (-1, window_width)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36. (L1) **Import `crim` and `medv` columns of the BostonHousing dataset as a dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(BOSTON_URL, usecols=['crim', 'medv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "37. (L2) **Get the number of rows, columns, datatype and summary statistics of each column of the `Cars93` dataset. Also get the numpy array and list equivalent of the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "CARS93_URL = \"https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv\"\n",
    "cars = pd.read_csv(CARS93_URL)\n",
    "\n",
    "print(\n",
    "    cars.info(),\n",
    "    '\\n',\n",
    "    cars.describe(),\n",
    "    '\\n',\n",
    "    cars.to_numpy(),\n",
    "    '\\n',\n",
    "    cars.to_numpy().tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38. (L1) **Which manufacturer, model and type has the highest Price? What is the row and column number of the cell with the highest Price value?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "cars = pd.read_csv(CARS93_URL)\n",
    "\n",
    "max_price_car = cars.loc[\n",
    "    np.argmax(  # Row of max price\n",
    "        cars['Price']\n",
    "    ), \n",
    "    ['Manufacturer', 'Model', 'Type']  # Which columns\n",
    "]\n",
    "print(max_price_car)\n",
    "np.where(  # Locate i,j of max Price cell\n",
    "    cars.values == np.max(cars['Price'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "39. (L2) **Rename the column `Type` as `CarType` in df and replace the `.` in column names with `_`.**\n",
    "\n",
    "Desired output:\n",
    "\n",
    "```python\n",
    " print(df.columns)\n",
    "#> Index(['Manufacturer', 'Model', 'CarType', 'Min_Price', 'Price', 'Max_Price',\n",
    "#>        'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
    "#>        'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
    "#>        'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
    "#>        'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
    "#>        'Make'],\n",
    "#>       dtype='object')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "cars = pd.read_csv(CARS93_URL)\n",
    "\n",
    "cars.columns = [\n",
    "    column.replace('.', '_')\n",
    "    for column in cars.columns\n",
    "]\n",
    "cars.rename(columns={'Type': 'CarType'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40. (L1) **Check if `df` has any missing values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "cars = pd.read_csv(CARS93_URL)\n",
    "\n",
    "np.any(\n",
    "    cars.isna()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41. (L2) **Count the number of missing values in each column of `df`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "cars = pd.read_csv(CARS93_URL)\n",
    "\n",
    "nans = cars.isna().astype(int).sum(axis=0)\n",
    "nans[\n",
    "    nans == nans.max()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "42. (L2) **Replace missing values in `Min.Price` and `Max.Price` columns with their respective mean.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "cars = pd.read_csv(CARS93_URL)\n",
    "\n",
    "for column in ['Min.Price', 'Max.Price']:\n",
    "    cars[column].fillna(\n",
    "        cars[column].mean().round(1),\n",
    "        inplace=True\n",
    "    )\n",
    "cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "43. (L3) **In `df`, use apply method to replace the missing values in `Min.Price` with the column’s mean and those in `Max.Price` with the column’s median.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "def filler(column: pd.Series):  # On deafult, apply happens PER COLUMN\n",
    "    if reducer := {\n",
    "        'Min.Price': np.nanmean,  # Drops NaN\n",
    "        'Max.Price': np.nanmedian,  # Ditto\n",
    "    }.get(column.name):\n",
    "        return column.fillna(value=reducer(column).round(1))\n",
    "    return column\n",
    "\n",
    "df.apply(filler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "44. (L2) **Get the first column (a) in `df` as a dataframe (rather than as a series).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "\n",
    "np.all(\n",
    "    pd.DataFrame(df[  # Brute-force\n",
    "        df.columns[0]\n",
    "    ]) == df[[df.columns[0]]]  # Shorthand\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "45. (L3) Actually 3 questions.\n",
    "\n",
    "* **In `df`, interchange columns `a` and `c`.**\n",
    "* **Create a generic function to interchange two columns, without hardcoding column names.**\n",
    "* **Sort the columns in reverse alphabetical order, that is column `e` first through column `a` last.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    e   d   c   b   a\n",
      "0   4   3   2   1   0\n",
      "1   9   8   7   6   5\n",
      "2  14  13  12  11  10\n",
      "3  19  18  17  16  15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "      <th>d</th>\n",
       "      <th>c</th>\n",
       "      <th>b</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    e   d   c   b   a\n",
       "0   4   3   2   1   0\n",
       "1   9   8   7   6   5\n",
       "2  14  13  12  11  10\n",
       "3  19  18  17  16  15"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "\n",
    "# Swapping function\n",
    "def swap_axes(dataframe: pd.DataFrame, axis_1: str, axis_2: str) -> None:\n",
    "    if axis_1 == axis_2:\n",
    "        return\n",
    "    dataframe[[axis_1, axis_2]] = df[[axis_2, axis_1]]\n",
    "    dataframe.rename(mapper={axis_1: axis_2, axis_2: axis_1}, inplace=True, axis=1)\n",
    "\n",
    "# Reversing with the function\n",
    "for mapping_index in range(len(df.columns)):\n",
    "    axis_1 = df.columns[mapping_index] \n",
    "    axis_2 = sorted(df.columns, reverse=True)[mapping_index]\n",
    "    swap_axes(df, axis_1=axis_1, axis_2=axis_2)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Sorting alphabetically, descending\n",
    "df.sort_index(axis=1, ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "46. (L2) **Change the pandas display settings on printing the dataframe `df` it shows a maximum of 10 rows and 10 columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min.Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>...</th>\n",
       "      <th>Rear.seat.room</th>\n",
       "      <th>Luggage.room</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>...</td>\n",
       "      <td>26.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Acura Integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3560.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Acura Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3375.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Audi 90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.7</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3405.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Audi 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3640.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>BMW 535i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Eurovan</td>\n",
       "      <td>Van</td>\n",
       "      <td>16.6</td>\n",
       "      <td>19.7</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3960.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Volkswagen Eurovan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Passat</td>\n",
       "      <td>Compact</td>\n",
       "      <td>17.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volkswagen Passat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Corrado</td>\n",
       "      <td>Sporty</td>\n",
       "      <td>22.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volkswagen Corrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>240</td>\n",
       "      <td>Compact</td>\n",
       "      <td>21.8</td>\n",
       "      <td>22.7</td>\n",
       "      <td>...</td>\n",
       "      <td>29.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volvo 240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>NaN</td>\n",
       "      <td>850</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>24.8</td>\n",
       "      <td>26.7</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3245.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volvo 850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Manufacturer    Model     Type  Min.Price  Price  ...  Rear.seat.room  \\\n",
       "0         Acura  Integra    Small       12.9   15.9  ...            26.5   \n",
       "1           NaN   Legend  Midsize       29.2   33.9  ...            30.0   \n",
       "2          Audi       90  Compact       25.9   29.1  ...            28.0   \n",
       "3          Audi      100  Midsize        NaN   37.7  ...            31.0   \n",
       "4           BMW     535i  Midsize        NaN   30.0  ...            27.0   \n",
       "..          ...      ...      ...        ...    ...  ...             ...   \n",
       "88   Volkswagen  Eurovan      Van       16.6   19.7  ...            34.0   \n",
       "89   Volkswagen   Passat  Compact       17.6   20.0  ...            31.5   \n",
       "90   Volkswagen  Corrado   Sporty       22.9   23.3  ...            26.0   \n",
       "91        Volvo      240  Compact       21.8   22.7  ...            29.5   \n",
       "92          NaN      850  Midsize       24.8   26.7  ...            30.0   \n",
       "\n",
       "    Luggage.room  Weight   Origin                Make  \n",
       "0            NaN  2705.0  non-USA       Acura Integra  \n",
       "1           15.0  3560.0  non-USA        Acura Legend  \n",
       "2           14.0  3375.0  non-USA             Audi 90  \n",
       "3           17.0  3405.0  non-USA            Audi 100  \n",
       "4           13.0  3640.0  non-USA            BMW 535i  \n",
       "..           ...     ...      ...                 ...  \n",
       "88           NaN  3960.0      NaN  Volkswagen Eurovan  \n",
       "89          14.0  2985.0  non-USA   Volkswagen Passat  \n",
       "90          15.0  2810.0  non-USA  Volkswagen Corrado  \n",
       "91          14.0  2985.0  non-USA           Volvo 240  \n",
       "92          15.0  3245.0  non-USA           Volvo 850  \n",
       "\n",
       "[93 rows x 27 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "47. (L2) **Suppress scientific notations like `e-03` in df and print upto 4 numbers after decimal.**\n",
    "\n",
    "Desired output:\n",
    "\n",
    "```python\n",
    "#>    random\n",
    "#> 0  0.0035\n",
    "#> 1  0.0000\n",
    "#> 2  0.0747\n",
    "#> 3  0.0000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   random\n",
       "0  0.1243\n",
       "1  0.0002\n",
       "2  0.0897\n",
       "3  0.8119"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "df = pd.DataFrame(np.random.random(4)**10, columns=['random'])\n",
    "\n",
    "pd.set_option('display.precision', 4)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "48. (L2) **Format the values in column `random` of `df` as percentages.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_507b1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_507b1_level0_col0\" class=\"col_heading level0 col0\" >random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_507b1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_507b1_row0_col0\" class=\"data row0 col0\" >66.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_507b1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_507b1_row1_col0\" class=\"data row1 col0\" >74.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_507b1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_507b1_row2_col0\" class=\"data row2 col0\" >51.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_507b1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_507b1_row3_col0\" class=\"data row3 col0\" >69.16%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f80b8731990>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
    "\n",
    "df.style.format({\n",
    "    'random': lambda value: f'{round((value * 100), 2)}%'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "49. (L1) **From `df`, filter the `Manufacturer`, `Model` and `Type` for every 20th row starting from 1st (row 0).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chrysler</td>\n",
       "      <td>LeBaron</td>\n",
       "      <td>Compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Prelude</td>\n",
       "      <td>Sporty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Mercury</td>\n",
       "      <td>Cougar</td>\n",
       "      <td>Midsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Subaru</td>\n",
       "      <td>Loyale</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Manufacturer    Model     Type\n",
       "0         Acura  Integra    Small\n",
       "20     Chrysler  LeBaron  Compact\n",
       "40        Honda  Prelude   Sporty\n",
       "60      Mercury   Cougar  Midsize\n",
       "80       Subaru   Loyale    Small"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "df[['Manufacturer', 'Model', 'Type']].iloc[::20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50. (L2) **In `df`, Replace NaNs with ‘missing’ in columns 'Manufacturer', 'Model' and 'Type' and create a index as a combination of these three columns and check if the index is a primary key.**\n",
    "\n",
    "Desired output:\n",
    "\n",
    "```python\n",
    "                       Manufacturer    Model     Type  Min.Price  Max.Price\n",
    "Acura_Integra_Small           Acura  Integra    Small       12.9       18.8\n",
    "missing_Legend_Midsize      missing   Legend  Midsize       29.2       38.7\n",
    "Audi_90_Compact                Audi       90  Compact       25.9       32.3\n",
    "Audi_100_Midsize               Audi      100  Midsize        NaN       44.6\n",
    "BMW_535i_Midsize                BMW     535i  Midsize        NaN        NaN\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min.Price</th>\n",
       "      <th>Max.Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Acura_Integra_Small</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_Legend_Midsize</th>\n",
       "      <td>missing</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>38.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi_90_Compact</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>32.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi_100_Midsize</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW_535i_Midsize</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volkswagen_Eurovan_Van</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Eurovan</td>\n",
       "      <td>Van</td>\n",
       "      <td>16.6</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volkswagen_Passat_Compact</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Passat</td>\n",
       "      <td>Compact</td>\n",
       "      <td>17.6</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volkswagen_Corrado_Sporty</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Corrado</td>\n",
       "      <td>Sporty</td>\n",
       "      <td>22.9</td>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volvo_240_Compact</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>240</td>\n",
       "      <td>Compact</td>\n",
       "      <td>21.8</td>\n",
       "      <td>23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_850_Midsize</th>\n",
       "      <td>missing</td>\n",
       "      <td>850</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>24.8</td>\n",
       "      <td>28.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Manufacturer    Model     Type  Min.Price  Max.Price\n",
       "Acura_Integra_Small              Acura  Integra    Small       12.9       18.8\n",
       "missing_Legend_Midsize         missing   Legend  Midsize       29.2       38.7\n",
       "Audi_90_Compact                   Audi       90  Compact       25.9       32.3\n",
       "Audi_100_Midsize                  Audi      100  Midsize        NaN       44.6\n",
       "BMW_535i_Midsize                   BMW     535i  Midsize        NaN        NaN\n",
       "...                                ...      ...      ...        ...        ...\n",
       "Volkswagen_Eurovan_Van      Volkswagen  Eurovan      Van       16.6       22.7\n",
       "Volkswagen_Passat_Compact   Volkswagen   Passat  Compact       17.6       22.4\n",
       "Volkswagen_Corrado_Sporty   Volkswagen  Corrado   Sporty       22.9       23.7\n",
       "Volvo_240_Compact                Volvo      240  Compact       21.8       23.5\n",
       "missing_850_Midsize            missing      850  Midsize       24.8       28.5\n",
       "\n",
       "[93 rows x 5 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0,1,2,3,5])\n",
    "\n",
    "df[['Manufacturer', 'Model', 'Type']] = df[['Manufacturer', 'Model', 'Type']].fillna(value='missing')\n",
    "df.set_index(\n",
    "    df['Manufacturer'] + '_' + df['Model'] + '_' + df['Type']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
